{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "## Overview\n",
    "\n",
    "In February of 2019, tens of thousands of domestic flights carried passengers around the country—every single day. Tens of thousands of aircraft being carefully tracked, monitored, organized and directed, and hundred of thousands or even millions of passengers count on those planes to get them where they're going. It's an incredible system, and most of the time it actually works. But when it doesn't, it hurts. Flight cancellations are extremely expensive, costing airlines a $1 billion per year. While flight cancellations due to weather may be inevitable, a significant portion of cancellations are due to circumstances under _our_ control. Modern air traffic control is a hundred years in the making and has certainly worked to minimize this issue already, but…can we do better?\n",
    "\n",
    "## Question\n",
    "\n",
    "Using data on American commercial flights, can we predict when a cancellation is likely to occur? As a bonus, can we predict _why_ the cancellation will occur?\n",
    "\n",
    "\n",
    "*This is your space to describe your intentions for the project, before writing a single line of code. What are you studying? What are you hoping to build? If you can't explain that clearly before you start digging into the data, you're going to have a hard time planning where to go with this.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data\n",
    "\n",
    "*Describe your data sources here and explain why they are relevant to the problem you are trying to solve.*\n",
    "\n",
    "*Your code should download the data and save it in data/raw. If you've got the data from an offline source, describe where it came from and what the files look like. Don't do anything to the raw data files just yet; that comes in the next step.*\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "My data set will be primarily based around the \"[Marketing Carrier On-Time Performance](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&DB_URL=)\" report released by the Bureau of Transportation Statistics. This database contains information on nearly every flight conducted by a significant U.S. carrier dating back to January 2018, which amounts to approximately 8 million observations. I expect I will supplement this dataset with additional features such as weather forecasts preceding a flight and additional statistics surrounding the model of plane for each flight.\n",
    "\n",
    "*After completing this step, be sure to edit `references/data_dictionary` to include descriptions of where you obtained your data and what information it contains.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/data/make_dataset.py\n",
    "\n",
    "# Imports\n",
    "from io import BytesIO\n",
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "\n",
    "def get_lookup_tables():\n",
    "    # Reporting carrier lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS'\n",
    "    # Reporting airline lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRLINE_ID'\n",
    "    # Airport ID lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT_ID'\n",
    "    # City Market ID lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_CITY_MARKET_ID'\n",
    "    # Airport lookup table (SEA -> Seattle-Tacoma International)\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT'\n",
    "    \n",
    "    lookups = [\n",
    "        'L_UNIQUE_CARRIERS',\n",
    "        'L_AIRLINE_ID',\n",
    "        'L_AIRPORT_ID',\n",
    "        'L_CITY_MARKET_ID',\n",
    "        'L_AIRPORT',\n",
    "        'L_AIRPORT_ID',\n",
    "        'L_CITY_MARKET_ID'\n",
    "    ]\n",
    "    lookup_base = 'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup='\n",
    "    for table in lookups:\n",
    "        download_lookup(lookup_base + table)\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_weather_forecasts():\n",
    "    # Weather forecast API\n",
    "    'https://darksky.net/dev/docs#time-machine-request'\n",
    "    key = 'c00a48b4e746f7a6b5a4caef59e18dc9'\n",
    "    # Example\n",
    "    request_format = f'''\n",
    "    https://api.darksky.net/forecast/{key}/{latitude},{longitude},{time}\n",
    "    '''\n",
    "    example = '''\n",
    "    https://api.darksky.net/forecast/0123456789abcdef9876543210fedcba/\n",
    "    42.3601,-71.0589,255657600?exclude=currently,flags\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def download_dataset(url, path, filename, overwrite='ask'):\n",
    "    \"\"\"\n",
    "    Downloads zip file from specified url and extracts csv file to raw data \n",
    "    directory\n",
    "    Input: \n",
    "        url: string of url from which to retrieve data\n",
    "        path: string of directory path to store file in\n",
    "        filename: string of desired filename\n",
    "        overwrite: parameter for whether or not to overwrite existing files, if\n",
    "            found. If 'y', any existing file with filename in path will be\n",
    "            overwritten. If 'n', function will do nothing. If 'ask', function\n",
    "            will prompt user to decide whether or not to replace file.\n",
    "    Output: dataset stored in raw data directory\n",
    "    \"\"\"\n",
    "    filepath = path + filename\n",
    "    file_exists = os.path.isfile(filepath)\n",
    "    if file_exists:\n",
    "        if overwrite == 'ask':\n",
    "            overwrite = input(f'{filename} already exists. Update? y/n: ')\n",
    "        if overwrite.lower() != 'y':\n",
    "            return\n",
    "                              \n",
    "    print(f'Beginning download of {filename}...')\n",
    "    try:\n",
    "        zip_f = urllib.request.urlopen(url)\n",
    "        with ZipFile(BytesIO(zip_f.read())) as my_zip_file:\n",
    "            for f in my_zip_file.namelist():\n",
    "                if '.csv' in f:\n",
    "                    with open(filepath, 'wb') as output:\n",
    "                        for line in my_zip_file.open(f).readlines():\n",
    "                            output.write(line)\n",
    "        print(f'Successfully wrote {filename} to {path}')\n",
    "                              \n",
    "    except urllib.request.HTTPError:\n",
    "        print(f'Failed to download {filename}')\n",
    "        return\n",
    "\n",
    "\n",
    "def get_flight_data_url(year, month):\n",
    "    '''\n",
    "    Generate URL to download pre-zipped csv of flight data for a given month as\n",
    "    provided by the Bureau of Transportation Statistics\n",
    "    Input: Year in format YYYY (int), Month in format of (M)M, i.e. 3, or 11\n",
    "    Output: download URL as a string\n",
    "    '''\n",
    "    base_url = 'http://transtats.bts.gov/PREZIP/'\n",
    "    tail = 'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_'\n",
    "    slug = f'{year}_{month}.zip'\n",
    "    return base_url + tail + slug\n",
    "    \n",
    "\n",
    "def get_flight_data(start, end, path):\n",
    "    '''\n",
    "    Downloads a variety of flight data tables from:\n",
    "    https://www.transtats.bts.gov/Fields.asp\n",
    "    '''\n",
    "    # Download all BTS datasets\n",
    "    for year in range(start, end):\n",
    "        for month in range(1,13):\n",
    "            filename = f'flight_data_{year}-{month}.csv'\n",
    "            url = get_flight_data_url(year, month)\n",
    "            download_dataset(url, path, filename)\n",
    "    pass\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that download data from one or more sources\n",
    "    and saves those datasets to the data/raw directory.\n",
    "    \"\"\"\n",
    "    path = '../data/raw/'\n",
    "    get_flight_data(2003, 2020, path)\n",
    "    # download_dataset_1(url)\n",
    "    # download_dataset_2(url)\n",
    "    # save_dataset_1('data/raw', filename)\n",
    "    # save_dataset_2('data/raw', filename)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CancellationCode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(df['DayofMonth'].value_counts()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('DayofMonth')['Cancelled'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub the Data\n",
    "\n",
    "*Look through the raw data files and see what you will need to do to them in order to have a workable data set. If your source data is already well-formatted, you may want to ask yourself why it hasn't already been analyzed and what other people may have overlooked when they were working on it. Are there other data sources that might give you more insights on some of the data you have here?*\n",
    "\n",
    "*The end goal of this step is to produce a [design matrix](https://en.wikipedia.org/wiki/Design_matrix), containing one column for every variable that you are modeling, including a column for the outputs, and one row for every observation in your data set. It needs to be in a format that won't cause any problems as you visualize and model your data.*\n",
    "\n",
    "## Features\n",
    "The following is a list of features I'd like to have in the design matrix:\n",
    "\n",
    "\n",
    "| Feature                               | Description                                                  | Type        | Purpose |\n",
    "| ------------------------------------- | ------------------------------------------------------------ | ----------- | ------- |\n",
    "| Airline ID                            | ID number to identify unique airline                         | Categorical | Key     |\n",
    "| AL_C_rate_day                         | Flight cancellation rate by this airline at this airport over past 24 hours | Continuous  | Feature |\n",
    "| AL_C_rate_7                           | Flight cancellation rate by this airline on this weekday 1 week ago | Continuous  | Feature |\n",
    "| AL_C_avg_rate_week                    | Flight cancellation rate by this airline at this airport over past 7 days | Continuous  | Feature |\n",
    "| AL_C_rate_28                          | Flight cancellation rate by this airline on this weekday 4 weeks ago | Continuous  | Feature |\n",
    "| AL_C_avg_rate_month                   | Flight cancellation rate by this airline at this airport over past 30 days | Continuous  | Feature |\n",
    "| AL_C_rate_364                         | Flight cancellation rate by this airline on this weekday 52 weeks ago | Continuous  | Feature |\n",
    "| AL_C_avg_rate_year                    | Flight cancellation rate by this airline at this airport over past 365 days | Continuous  | Feature |\n",
    "| Tail number                           | Unique airplane identifier ID                                | Categorical | Key     |\n",
    "| AP_C_rate_day                         | Flight cancellation rate by this airplane over past 24 hours | Continuous  | Feature |\n",
    "| AP_C_rate_7                           | Flight cancellation rate by this airplane on this weekday 1 week ago | Continuous  | Feature |\n",
    "| AP_C_avg_rate_week                    | Flight cancellation rate by this airplane at this airport over past 7 days | Continuous  | Feature |\n",
    "| AP_C_rate_28                          | Flight cancellation rate by this airplane on this weekday 4 weeks ago | Continuous  | Feature |\n",
    "| AP_C_avg_rate_month                   | Flight cancellation rate by this airplane at this airport over past 30 days | Continuous  | Feature |\n",
    "| AP_C_rate_364                         | Flight cancellation rate by this airplane on this weekday 52 weeks ago | Continuous  | Feature |\n",
    "| AP_C_avg_rate_year                    | Flight cancellation rate by this airplane at this airport over past 365 days | Continuous  | Feature |\n",
    "| Origin Airport ID                     | Unique airport identifier ID for flight origin               | Categorical | Key     |\n",
    "| orig_C_rate_day                       | Flight cancellation rate for flights departing from origin airport over past 24 hours | Continuous  | Feature |\n",
    "| repeat same pattern as above          |                                                              |             |         |\n",
    "| Origin City Market                    | ID for area that may be served by several airlines           | Categorical | Key     |\n",
    "| OCM_C_rate_day                        | Flight cancellation rate for flights departing from origin city market over past 24 hours | Continuous  | Feature |\n",
    "| repeat same pattern as above          |                                                              |             |         |\n",
    "| Dest Airport ID                       | Unique airport identifier ID for destination                 | Categorical | Key     |\n",
    "| dest_C_rate_day                       | Flight cancellation rate for flights heading to destination airport over past 24 hours | Continuous  | Feature |\n",
    "| repeat same pattern as above          |                                                              |             |         |\n",
    "| Dest City Market                      | ID for area that may be served by several airlines           | Categorical | Key     |\n",
    "| DCM_C_rate_day                        | Flight cancellation rate for flights heading to destination city market over past 24 hours | Continuous  | Feature |\n",
    "| repeat same pattern as above          |                                                              |             |         |\n",
    "| Departure time                        | Scheduled departure time                                     | ?           |         |\n",
    "| Airtime                               | Planned time in air, in minutes                              | Continuous  |         |\n",
    "| Distance                              | Planned route distance                                       | Continuous  |         |\n",
    "| On-time incoming arrival percentage   | Percent of flights that arrive at departure airport on-time  | Continuous  |         |\n",
    "| On-time outgoing departure percentage | Percent of flights that depart from departure airport on-time | Continuous  |         |\n",
    "| Historical cancellation percentages   | All time average                                             | Continuous  |         |\n",
    "|                                       | 1 day ago                                                    | Continuous  |         |\n",
    "|                                       | 7 days ago                                                   | Continuous  |         |\n",
    "|                                       | 30 days ago                                                  | Continuous  |         |\n",
    "|                                       | 364 days ago                                                 | Continuous  |         |\n",
    "|                                       | For this airline                                             | Continuous  |         |\n",
    "|                                       | From this airport                                            | Continuous  |         |\n",
    "|                                       | To that airport                                              | Continuous  |         |\n",
    "|                                       | On this airplane (tail number)                               | Continuous  |         |\n",
    "|                                       | On this airplane model                                       | Continuous  |         |\n",
    "| Historical delays (goes back to 2003) | The average number of minutes that a similar incoming flight has been delayed (in minutes) over the avove time periods, for the reasons: carrier delay, weather delay, national air system delay, security delay, and late aircraft delay |             |         |\n",
    "|                                       |                                                              |             |         |\n",
    "| Weather Forecast                      | What the weather forecast was ~24 hours ago, in degrees      | Continuous  |         |\n",
    "| Other airline/craft statistics        |                                                              |             |         |\n",
    "| Cancelled                             | Boolean for whether or not flight is cancelled, 1=Yes        | Boolean     |         |\n",
    "| Cancellation Code                     | Reason for cancellation (carrier, weather, national air system, security) | Categorical |         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/features/build_features.py\n",
    "\n",
    "# Imports\n",
    "import csv\n",
    "from os import listdir\n",
    "import subprocess\n",
    "import sys\n",
    "from psycopg2 import connect\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "\n",
    "# Airline cancellation rate\n",
    "def get_avg_cancellation_rate(by, time):\n",
    "    pass\n",
    "\n",
    "def get_past_cancellation_rate(by, time):\n",
    "    pass\n",
    "\n",
    "\n",
    "\n",
    "def run_query(query, params, engine):\n",
    "    '''\n",
    "    Opens a connection to database to run a query, q\n",
    "    Input: \n",
    "        query (str), a SQL command that requests output\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "            and port\n",
    "    Output: a pandas dataframe containing the query output\n",
    "    '''\n",
    "    \n",
    "    with connect(params) as conn:\n",
    "#         conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "#         cur = conn.cursor()\n",
    "#         cur.execute(query)\n",
    "        return pd.read_sql()\n",
    "\n",
    "    \n",
    "def show_tables():\n",
    "    # Returns a list of all tables and views in our database\n",
    "    q = \"\"\"\n",
    "    SELECT tablename \n",
    "    FROM pg_catalog.pg_tables \n",
    "    WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';\n",
    "    \"\"\"\n",
    "    return run_query(q)\n",
    "\n",
    "\n",
    "def run_command(command, params):\n",
    "    '''\n",
    "    Opens a connection to database to run a command with no output\n",
    "    Input: \n",
    "        command (str), a SQL query that commits an action\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "            and port\n",
    "    '''\n",
    "    with connect(**params) as conn:\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(command)\n",
    "        pass\n",
    "\n",
    "        \n",
    "def create_table(table, params):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    table_query = f\"\"\"\n",
    "        CREATE TABLE {table}(\n",
    "            year NUMERIC,\n",
    "            quarter NUMERIC,\n",
    "            month NUMERIC,\n",
    "            dayofmonth NUMERIC,\n",
    "            dayofweek NUMERIC,\n",
    "            flightdate DATE NOT NULL,\n",
    "            reporting_airline VARCHAR,\n",
    "            dot_id_reporting_airline VARCHAR,\n",
    "            iata_code_reporting_airline VARCHAR,\n",
    "            tail_number VARCHAR,\n",
    "            flight_number_reporting_airline VARCHAR NOT NULL,\n",
    "            originairportid VARCHAR,\n",
    "            originairportseqid VARCHAR,\n",
    "            origincitymarketid VARCHAR,\n",
    "            origin VARCHAR,\n",
    "            origincityname VARCHAR,\n",
    "            originstate VARCHAR,\n",
    "            originstatefips VARCHAR,\n",
    "            originstatename VARCHAR,\n",
    "            originwac VARCHAR,\n",
    "            destairportid VARCHAR,\n",
    "            destairportseqid VARCHAR,\n",
    "            destcitymarketid VARCHAR,\n",
    "            dest VARCHAR,\n",
    "            destcityname VARCHAR,\n",
    "            deststate VARCHAR,\n",
    "            deststatefips VARCHAR,\n",
    "            deststatename VARCHAR,\n",
    "            destwac VARCHAR,\n",
    "            crsdeptime NUMERIC,\n",
    "            deptime NUMERIC,\n",
    "            depdelay NUMERIC,\n",
    "            depdelayminutes NUMERIC,\n",
    "            depdel15 NUMERIC,\n",
    "            departuredelaygroups NUMERIC,\n",
    "            deptimeblk VARCHAR,\n",
    "            taxiout NUMERIC,\n",
    "            wheelsoff NUMERIC,\n",
    "            wheelson NUMERIC,\n",
    "            taxiin NUMERIC,\n",
    "            crsarrtime NUMERIC,\n",
    "            arrtime NUMERIC,\n",
    "            arrdelay NUMERIC,\n",
    "            arrdelayminutes NUMERIC,\n",
    "            arrdel15 NUMERIC,\n",
    "            arrivaldelaygroups NUMERIC,\n",
    "            arrtimeblk VARCHAR,\n",
    "            cancelled NUMERIC,\n",
    "            cancellationcode NUMERIC,\n",
    "            diverted NUMERIC,\n",
    "            crselapsedtime NUMERIC,\n",
    "            actualelapsedtime NUMERIC,\n",
    "            airtime NUMERIC,\n",
    "            flights NUMERIC,\n",
    "            distance NUMERIC,\n",
    "            distancegroup NUMERIC,\n",
    "            carrierdelay NUMERIC,\n",
    "            weatherdelay NUMERIC,\n",
    "            nasdelay NUMERIC,\n",
    "            securitydelay NUMERIC,\n",
    "            lateaircraftdelay NUMERIC,\n",
    "            firstdeptime NUMERIC,\n",
    "            totaladdgtime NUMERIC,\n",
    "            longestaddgtime NUMERIC,\n",
    "            divairportlandings VARCHAR,\n",
    "            divreacheddest VARCHAR,\n",
    "            divactualelapsedtime VARCHAR,\n",
    "            divarrdelay VARCHAR,\n",
    "            divdistance VARCHAR,\n",
    "            div1airport VARCHAR,\n",
    "            div1airportid VARCHAR,\n",
    "            div1airportseqid VARCHAR,\n",
    "            div1wheelson VARCHAR,\n",
    "            div1totalgtime VARCHAR,\n",
    "            div1longestgtime VARCHAR,\n",
    "            div1wheelsoff VARCHAR,\n",
    "            div1tailnum VARCHAR,\n",
    "            div2airport VARCHAR,\n",
    "            div2airportid VARCHAR,\n",
    "            div2airportseqid VARCHAR,\n",
    "            div2wheelson VARCHAR,\n",
    "            div2totalgtime VARCHAR,\n",
    "            div2longestgtime VARCHAR,\n",
    "            div2wheelsoff VARCHAR,\n",
    "            div2tailnum VARCHAR,\n",
    "            div3airport VARCHAR,\n",
    "            div3airportid VARCHAR,\n",
    "            div3airportseqid VARCHAR,\n",
    "            div3wheelson VARCHAR,\n",
    "            div3totalgtime VARCHAR,\n",
    "            div3longestgtime VARCHAR,\n",
    "            div3wheelsoff VARCHAR,\n",
    "            div3tailnum VARCHAR,\n",
    "            div4airport VARCHAR,\n",
    "            div4airportid VARCHAR,\n",
    "            div4airportseqid VARCHAR,\n",
    "            div4wheelson VARCHAR,\n",
    "            div4totalgtime VARCHAR,\n",
    "            div4longestgtime VARCHAR,\n",
    "            div4wheelsoff VARCHAR,\n",
    "            div4tailnum VARCHAR,\n",
    "            div5airport VARCHAR,\n",
    "            div5airportid VARCHAR,\n",
    "            div5airportseqid VARCHAR,\n",
    "            div5wheelson VARCHAR,\n",
    "            div5totalgtime VARCHAR,\n",
    "            div5longestgtime VARCHAR,\n",
    "            div5wheelsoff VARCHAR,\n",
    "            div5tailnum VARCHAR,\n",
    "            empty VARCHAR,\n",
    "            PRIMARY KEY(flightdate, flight_number_reporting_airline)\n",
    "        );\n",
    "        \"\"\"\n",
    "    run_command(table_query, params)\n",
    "    pass\n",
    "    \n",
    "    \n",
    "def check_table_exists(table, cursor):\n",
    "    '''\n",
    "    Executes a query and checks if item is in returned results\n",
    "    Input: \n",
    "        query (str), a SQL query returning list of items to look within\n",
    "        item (str), the name of the item to check if exists\n",
    "        cursor, a psycogp2 cursor object\n",
    "    Output: boolean, True if item exists\n",
    "    '''\n",
    "    query = \"\"\"\n",
    "    SELECT tablename \n",
    "    FROM pg_catalog.pg_tables \n",
    "    WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    items = [i[0] for i in cursor.fetchall()]\n",
    "    print(f'Found tables: {items}')\n",
    "    exists = table in items\n",
    "    return exists\n",
    "\n",
    "\n",
    "def check_db_exists(db, cursor):\n",
    "    '''\n",
    "    Executes a query and checks if item is in returned results\n",
    "    Input: \n",
    "        query (str), a SQL query returning list of items to look within\n",
    "        item (str), the name of the item to check if exists\n",
    "        cursor, a psycogp2 cursor object\n",
    "    Output: boolean, True if item exists\n",
    "    '''\n",
    "    query = 'SELECT datname FROM pg_database;'\n",
    "    cursor.execute(query)\n",
    "    items = [i[0] for i in cursor.fetchall()]\n",
    "    print(f'Found items: {items}')\n",
    "    exists = db in items\n",
    "    return exists\n",
    "\n",
    "    \n",
    "def load_table(file, path, params, overwrite='ask'):\n",
    "    ''' \n",
    "    Loads a csv into a SQL table\n",
    "    Input:\n",
    "        file (str), filename of csv to load\n",
    "        path (str), relative directory to find file in\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "            and port\n",
    "        overwrite (str): parameter for whether or not to overwrite existing \n",
    "            files, if found. If 'y', any existing file with filename in path \n",
    "            will be overwritten. If 'n', function will do nothing. If 'ask', \n",
    "            function will prompt user to decide whether or not to replace file.\n",
    "    '''\n",
    "    dbname = params['dbname']\n",
    "#     path = 'Users/scottbutters/src/project-03/data/raw/'\n",
    "    file_path = path + file\n",
    "    table_name = f'flights_{file[12:-4]}'.replace('-','_')\n",
    "    print(table_name)\n",
    "    \n",
    "    try:\n",
    "        with connect(**params) as conn:\n",
    "            conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "            print(f\"Connecting to database {params['dbname']}\")\n",
    "            cur = conn.cursor()\n",
    "            exists = check_table_exists(table_name, cur)\n",
    "            if exists:\n",
    "                if overwrite == 'ask':\n",
    "                    overwrite = input(f'{table_name} already exists. Update? y/n: ')\n",
    "                if overwrite.lower() != 'y':\n",
    "                    return\n",
    "#             if check_existence(q, table_name, cur):\n",
    "                # Truncate the table first\n",
    "                cur.execute(f'TRUNCATE {table_name} CASCADE;')\n",
    "                print(f'Truncated {table_name}')\n",
    "            command = f'csvsql --db postgresql:///{dbname}'\n",
    "            params = f'--tables {table_name} --insert {file_path}'\n",
    "            args = '--no-constraints --overwrite'\n",
    "#             subprocess.call(f'{command} {params} {args}')\n",
    "            subprocess.call(f'{command} {params} {args}', shell=True)\n",
    "\n",
    "#                 create_table(table_name, params)\n",
    "                \n",
    "\n",
    "#                 cur.execute(f'CREATE TABLE {table_name};')\n",
    "#                 print(f'Created table {table_name}')\n",
    "#             with open(file_path, 'r') as f:\n",
    "#                 next(f)  # Skip the header row.\n",
    "#                 cur.copy_from(f, table_name, sep=',')\n",
    "                  \n",
    "                  \n",
    "#                 c = f\"\"\"\n",
    "#                     COPY {table_name} FROM STDIN WITH CSV HEADER\n",
    "#                     \"\"\"\n",
    "#                 cur.copy_expert(c, f)\n",
    "            print(f'Loaded data into {table_name}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {str(e)}')\n",
    "        sys.exit(1)\n",
    "    pass\n",
    "                  \n",
    "\n",
    "def load_csvs(table, path, params, overwrite='ask'):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    dbname = params['dbname']\n",
    "    q = \"\"\"\n",
    "        SELECT tablename \n",
    "        FROM pg_catalog.pg_tables \n",
    "        WHERE schemaname != 'pg_catalog' \n",
    "        AND schemaname != 'information_schema';\n",
    "        \"\"\"\n",
    "    try:\n",
    "        with connect(**params) as conn:\n",
    "            conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "            print(f'Connecting to database {dbname}')\n",
    "            cur = conn.cursor()\n",
    "            exists = check_existence(q, table, cur)\n",
    "            if exists:\n",
    "                print(f'Table {table} already exists.')\n",
    "            if exists:\n",
    "                if overwrite == 'ask':\n",
    "                    question = f'''\n",
    "                    Update? WARNING: This will take a while. y/n: \n",
    "                    '''\n",
    "                    overwrite = input(question)\n",
    "                if overwrite.lower() != 'y':\n",
    "                    return\n",
    "#             if check_existence(q, table_name, cur):\n",
    "                # Truncate the table first\n",
    "                cur.execute(f'TRUNCATE {table} CASCADE;')\n",
    "                print(f'Truncated {table}')\n",
    "            \n",
    "            # Write table\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                print('Running console command:')\n",
    "                print(f'Collecting csvs from {path}...\\n',\n",
    "                      f'Adding data to table {table}')\n",
    "                csvstack = f'csvstack {path}*.csv'\n",
    "                csvsql = f'csvsql --db postgresql:///{dbname}'\n",
    "                args = f'--tables {table} --insert'\n",
    "                command = f'{csvstack} | {csvsql}'\n",
    "                retcode = subprocess.call([command, args])\n",
    "                print('Success!')\n",
    "            except:\n",
    "                print('Write to table failed.')\n",
    "                print(f'Error: {retcode}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {str(e)}')\n",
    "        sys.exit(1)\n",
    "    pass\n",
    "                  \n",
    "                  \n",
    "def make_table(path, file, engine, table):\n",
    "    df = pd.read_csv(path + file)\n",
    "\n",
    "    drop_cols = [\n",
    "        'DOT_ID_Reporting_Airline',\n",
    "        'IATA_CODE_Reporting_Airline', \n",
    "        'OriginAirportSeqID', \n",
    "        'OriginStateFips',\n",
    "        'OriginWac',\n",
    "        'DestAirportSeqID', \n",
    "        'DestStateFips',\n",
    "        'DestWac',\n",
    "        'TaxiOut',\n",
    "        'WheelsOff', \n",
    "        'WheelsOn', \n",
    "        'TaxiIn'\n",
    "    ]\n",
    "\n",
    "    short_df = df[df.columns[:61]].drop(drop_cols, axis=1)\n",
    "\n",
    "    shorter_df = short_df[\n",
    "        short_df['Origin'].str.contains('SEA') |\n",
    "        short_df['Dest'].str.contains('SEA')\n",
    "    ]\n",
    "\n",
    "    index = (shorter_df['FlightDate'].astype(str) \n",
    "             + '_' + shorter_df['Flight_Number_Reporting_Airline'].astype(str))\n",
    "\n",
    "    shorter_df.set_index(\n",
    "        keys=index,\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    shorter_df.columns = [col.lower() for col in shorter_df.columns]\n",
    "    \n",
    "    # Define types\n",
    "    types = {\n",
    "        'year': sqlalchemy.types.INTEGER(),\n",
    "        'quarter': sqlalchemy.types.INTEGER(),\n",
    "        'month': sqlalchemy.types.INTEGER(),\n",
    "        'dayofmonth': sqlalchemy.types.INTEGER(),\n",
    "        'dayofweek': sqlalchemy.types.INTEGER(),\n",
    "        'flightdate': sqlalchemy.DateTime(),\n",
    "        'reporting_airline': sqlalchemy.types.VARCHAR(),\n",
    "        'tail_number': sqlalchemy.types.VARCHAR(),\n",
    "        'flight_number_reporting_airline': sqlalchemy.types.VARCHAR(),\n",
    "        'originairportid': sqlalchemy.types.VARCHAR(),\n",
    "        'origincitymarketid': sqlalchemy.types.VARCHAR(),\n",
    "        'origin': sqlalchemy.types.VARCHAR(),\n",
    "        'origincityname': sqlalchemy.types.VARCHAR(),\n",
    "        'originstate': sqlalchemy.types.VARCHAR(),\n",
    "        'originstatename': sqlalchemy.types.VARCHAR(),\n",
    "        'destairportid': sqlalchemy.types.VARCHAR(),\n",
    "        'destcitymarketid': sqlalchemy.types.VARCHAR(),\n",
    "        'dest': sqlalchemy.types.VARCHAR(),\n",
    "        'destcityname': sqlalchemy.types.VARCHAR(),\n",
    "        'deststate': sqlalchemy.types.VARCHAR(),\n",
    "        'deststatename': sqlalchemy.types.VARCHAR(),\n",
    "        'crsdeptime': sqlalchemy.types.INTEGER(),\n",
    "        'deptime': sqlalchemy.types.INTEGER(),\n",
    "        'depdelay': sqlalchemy.types.INTEGER(),\n",
    "        'depdelayminutes': sqlalchemy.types.INTEGER(),\n",
    "        'depdel15': sqlalchemy.types.BOOLEAN(),\n",
    "        'departuredelaygroups': sqlalchemy.types.INTEGER(),\n",
    "        'deptimeblk': sqlalchemy.types.VARCHAR(),\n",
    "        'crsarrtime': sqlalchemy.types.INTEGER(),\n",
    "        'arrtime': sqlalchemy.types.INTEGER(),\n",
    "        'arrdelay': sqlalchemy.types.INTEGER(),\n",
    "        'arrdelayminutes': sqlalchemy.types.INTEGER(),\n",
    "        'arrdel15': sqlalchemy.types.BOOLEAN(),\n",
    "        'arrivaldelaygroups': sqlalchemy.types.INTEGER(),\n",
    "        'arrtimeblk': sqlalchemy.types.VARCHAR(),\n",
    "        'cancelled': sqlalchemy.types.INTEGER(),\n",
    "        'cancellationcode': sqlalchemy.types.VARCHAR(),\n",
    "        'diverted': sqlalchemy.types.VARCHAR(),\n",
    "        'crselapsedtime': sqlalchemy.types.VARCHAR(),\n",
    "        'actualelapsedtime': sqlalchemy.types.INTEGER(),\n",
    "        'airtime': sqlalchemy.types.INTEGER(),\n",
    "        'flights': sqlalchemy.types.INTEGER(),\n",
    "        'distance': sqlalchemy.types.INTEGER(),\n",
    "        'distancegroup': sqlalchemy.types.INTEGER(),\n",
    "        'carrierdelay': sqlalchemy.types.VARCHAR(),\n",
    "        'weatherdelay': sqlalchemy.types.VARCHAR(),\n",
    "        'nasdelay': sqlalchemy.types.VARCHAR(),\n",
    "        'securitydelay': sqlalchemy.types.VARCHAR(),\n",
    "        'lateaircraftdelay': sqlalchemy.types.VARCHAR(),\n",
    "    }\n",
    "                  \n",
    "    # Add to SQL table\n",
    "    shorter_df.to_sql(\n",
    "        table, engine, if_exists='append', dtype=types, index=False)\n",
    "    print(f'Added {file} to table {table}')\n",
    "                  \n",
    "    int_path = '../data/interim/'\n",
    "    shorter_df.to_csv(f'{int_path}reduced_{file}')\n",
    "    print(f'Wrote {file} to {int_path}')\n",
    "    pass\n",
    "\n",
    "                  \n",
    "def create_db(dbname, params):\n",
    "    '''\n",
    "    Connects to psql as default user and creates new database if it doesn't\n",
    "    already exist\n",
    "    Input:\n",
    "        dbname (string), name of new database\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "        and port\n",
    "    Output: database created in psql\n",
    "    '''\n",
    "    \n",
    "    temp_params = params.copy()\n",
    "    temp_params['dbname'] = 'postgres'\n",
    "    with connect(**temp_params) as conn:\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cur = conn.cursor()\n",
    "        exists = check_db_exists(dbname, cur)\n",
    "        if not exists:\n",
    "            cur.execute(f'CREATE DATABASE {dbname}')\n",
    "            print(f'Created database {dbname}')\n",
    "    pass\n",
    "        \n",
    "\n",
    "def build_raw_database():\n",
    "    '''\n",
    "    Constructs database from raw data CSVs previously downloaded\n",
    "    '''\n",
    "    path = '../data/raw/'\n",
    "    params = {\n",
    "        'user': 'scottbutters',\n",
    "        'host': '127.0.0.1',\n",
    "        'port': 5432,\n",
    "        'dbname': 'raw_flight_data'\n",
    "    }\n",
    "    table_name = 'flights'\n",
    "    \n",
    "    connection_string = f\"postgresql:///{params['dbname']}\"\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Create db if DNE yet\n",
    "    create_db(dbname=params['dbname'], params=params)\n",
    "    \n",
    "    # Check whether table exists and prompt about dropping\n",
    "    with connect(**params) as conn:\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        print(f\"Connecting to database {params['dbname']}\")\n",
    "        cur = conn.cursor()\n",
    "        exists = check_table_exists(table_name, cur)\n",
    "        if exists:\n",
    "            overwrite = input(f'{table_name} already exists. Update? y/n: ')\n",
    "            if overwrite.lower() != 'y':\n",
    "                return\n",
    "            run_command('DROP TABLE flights;', params)\n",
    "\n",
    "    # Collect list of csvs\n",
    "    files = [f for f in listdir(path) if '.csv' in f]\n",
    "    files = sorted(files)\n",
    "    \n",
    "    # Shrink files and load all into SQL table\n",
    "    for file in files:\n",
    "#         make_table(path + file, engine)\n",
    "#         load_table(file, path, params)\n",
    "#     load_table(files[0], path, params)\n",
    "#     load_csvs('flights', path, params)\n",
    "        make_table(path, file, engine, table_name)\n",
    "    pass\n",
    "        \n",
    "        \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/raw, cleans them,\n",
    "    and converts the data into a design matrix that is ready for modeling.\n",
    "    \"\"\"\n",
    "    build_raw_database()\n",
    "#     data = clean_data()\n",
    "#     create_\n",
    "    \n",
    "    # clean_dataset_1('data/raw', filename)\n",
    "    # clean_dataset_2('data/raw', filename)\n",
    "    # save_cleaned_data_1('data/interim', filename)\n",
    "    # save_cleaned_data_2('data/interim', filename)\n",
    "    # build_features()\n",
    "    # save_features('data/processed')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'quarter', 'month', 'dayofmonth', 'dayofweek', 'flightdate',\n",
       "       'reporting_airline', 'tail_number', 'flight_number_reporting_airline',\n",
       "       'originairportid', 'origincitymarketid', 'origin', 'origincityname',\n",
       "       'originstate', 'originstatename', 'destairportid', 'destcitymarketid',\n",
       "       'dest', 'destcityname', 'deststate', 'deststatename', 'crsdeptime',\n",
       "       'deptime', 'depdelay', 'depdelayminutes', 'depdel15',\n",
       "       'departuredelaygroups', 'deptimeblk', 'crsarrtime', 'arrtime',\n",
       "       'arrdelay', 'arrdelayminutes', 'arrdel15', 'arrivaldelaygroups',\n",
       "       'arrtimeblk', 'cancelled', 'cancellationcode', 'diverted',\n",
       "       'crselapsedtime', 'actualelapsedtime', 'airtime', 'flights', 'distance',\n",
       "       'distancegroup', 'carrierdelay', 'weatherdelay', 'nasdelay',\n",
       "       'securitydelay', 'lateaircraftdelay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorter_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diverted</th>\n",
       "      <th>crselapsedtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01_155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-02_155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03_155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-04_155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-05_155</th>\n",
       "      <td>0.0</td>\n",
       "      <td>227.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                diverted  crselapsedtime\n",
       "2003-01-01_155       0.0           227.0\n",
       "2003-01-02_155       0.0           227.0\n",
       "2003-01-03_155       0.0           227.0\n",
       "2003-01-04_155       0.0           227.0\n",
       "2003-01-05_155       0.0           227.0"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorter_df.iloc[:,37:39].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found items: ['postgres', 'scottbutters', 'template1', 'template0', 'names', 'store', 'raw_flight_data', 'test']\n",
      "Connecting to database raw_flight_data\n",
      "Found tables: ['flights_2003_1', 'flights_2003_10', 'flights_2003_11', 'flights']\n",
      "flights already exists. Update? y/n: y\n",
      "Added flight_data_2003-1.csv to table flights\n",
      "Wrote flight_data_2003-1.csv to ../data/interim/\n",
      "Added flight_data_2003-10.csv to table flights\n",
      "Wrote flight_data_2003-10.csv to ../data/interim/\n",
      "Added flight_data_2003-11.csv to table flights\n",
      "Wrote flight_data_2003-11.csv to ../data/interim/\n",
      "Added flight_data_2003-12.csv to table flights\n",
      "Wrote flight_data_2003-12.csv to ../data/interim/\n",
      "Added flight_data_2003-2.csv to table flights\n",
      "Wrote flight_data_2003-2.csv to ../data/interim/\n",
      "Added flight_data_2003-3.csv to table flights\n",
      "Wrote flight_data_2003-3.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (37,38) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2003-4.csv to table flights\n",
      "Wrote flight_data_2003-4.csv to ../data/interim/\n",
      "Added flight_data_2003-5.csv to table flights\n",
      "Wrote flight_data_2003-5.csv to ../data/interim/\n",
      "Added flight_data_2003-6.csv to table flights\n",
      "Wrote flight_data_2003-6.csv to ../data/interim/\n",
      "Added flight_data_2003-7.csv to table flights\n",
      "Wrote flight_data_2003-7.csv to ../data/interim/\n",
      "Added flight_data_2003-8.csv to table flights\n",
      "Wrote flight_data_2003-8.csv to ../data/interim/\n",
      "Added flight_data_2003-9.csv to table flights\n",
      "Wrote flight_data_2003-9.csv to ../data/interim/\n",
      "Added flight_data_2004-1.csv to table flights\n",
      "Wrote flight_data_2004-1.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2004-10.csv to table flights\n",
      "Wrote flight_data_2004-10.csv to ../data/interim/\n",
      "Added flight_data_2004-11.csv to table flights\n",
      "Wrote flight_data_2004-11.csv to ../data/interim/\n",
      "Added flight_data_2004-12.csv to table flights\n",
      "Wrote flight_data_2004-12.csv to ../data/interim/\n",
      "Added flight_data_2004-2.csv to table flights\n",
      "Wrote flight_data_2004-2.csv to ../data/interim/\n",
      "Added flight_data_2004-3.csv to table flights\n",
      "Wrote flight_data_2004-3.csv to ../data/interim/\n",
      "Added flight_data_2004-4.csv to table flights\n",
      "Wrote flight_data_2004-4.csv to ../data/interim/\n",
      "Added flight_data_2004-5.csv to table flights\n",
      "Wrote flight_data_2004-5.csv to ../data/interim/\n",
      "Added flight_data_2004-6.csv to table flights\n",
      "Wrote flight_data_2004-6.csv to ../data/interim/\n",
      "Added flight_data_2004-7.csv to table flights\n",
      "Wrote flight_data_2004-7.csv to ../data/interim/\n",
      "Added flight_data_2004-8.csv to table flights\n",
      "Wrote flight_data_2004-8.csv to ../data/interim/\n",
      "Added flight_data_2004-9.csv to table flights\n",
      "Wrote flight_data_2004-9.csv to ../data/interim/\n",
      "Added flight_data_2005-1.csv to table flights\n",
      "Wrote flight_data_2005-1.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2005-10.csv to table flights\n",
      "Wrote flight_data_2005-10.csv to ../data/interim/\n",
      "Added flight_data_2005-11.csv to table flights\n",
      "Wrote flight_data_2005-11.csv to ../data/interim/\n",
      "Added flight_data_2005-12.csv to table flights\n",
      "Wrote flight_data_2005-12.csv to ../data/interim/\n",
      "Added flight_data_2005-2.csv to table flights\n",
      "Wrote flight_data_2005-2.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (37,48) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2005-3.csv to table flights\n",
      "Wrote flight_data_2005-3.csv to ../data/interim/\n",
      "Added flight_data_2005-4.csv to table flights\n",
      "Wrote flight_data_2005-4.csv to ../data/interim/\n",
      "Added flight_data_2005-5.csv to table flights\n",
      "Wrote flight_data_2005-5.csv to ../data/interim/\n",
      "Added flight_data_2005-6.csv to table flights\n",
      "Wrote flight_data_2005-6.csv to ../data/interim/\n",
      "Added flight_data_2005-7.csv to table flights\n",
      "Wrote flight_data_2005-7.csv to ../data/interim/\n",
      "Added flight_data_2005-8.csv to table flights\n",
      "Wrote flight_data_2005-8.csv to ../data/interim/\n",
      "Added flight_data_2005-9.csv to table flights\n",
      "Wrote flight_data_2005-9.csv to ../data/interim/\n",
      "Added flight_data_2006-1.csv to table flights\n",
      "Wrote flight_data_2006-1.csv to ../data/interim/\n",
      "Added flight_data_2006-10.csv to table flights\n",
      "Wrote flight_data_2006-10.csv to ../data/interim/\n",
      "Added flight_data_2006-11.csv to table flights\n",
      "Wrote flight_data_2006-11.csv to ../data/interim/\n",
      "Added flight_data_2006-12.csv to table flights\n",
      "Wrote flight_data_2006-12.csv to ../data/interim/\n",
      "Added flight_data_2006-2.csv to table flights\n",
      "Wrote flight_data_2006-2.csv to ../data/interim/\n",
      "Added flight_data_2006-3.csv to table flights\n",
      "Wrote flight_data_2006-3.csv to ../data/interim/\n",
      "Added flight_data_2006-4.csv to table flights\n",
      "Wrote flight_data_2006-4.csv to ../data/interim/\n",
      "Added flight_data_2006-5.csv to table flights\n",
      "Wrote flight_data_2006-5.csv to ../data/interim/\n",
      "Added flight_data_2006-6.csv to table flights\n",
      "Wrote flight_data_2006-6.csv to ../data/interim/\n",
      "Added flight_data_2006-7.csv to table flights\n",
      "Wrote flight_data_2006-7.csv to ../data/interim/\n",
      "Added flight_data_2006-8.csv to table flights\n",
      "Wrote flight_data_2006-8.csv to ../data/interim/\n",
      "Added flight_data_2006-9.csv to table flights\n",
      "Wrote flight_data_2006-9.csv to ../data/interim/\n",
      "Added flight_data_2007-1.csv to table flights\n",
      "Wrote flight_data_2007-1.csv to ../data/interim/\n",
      "Added flight_data_2007-10.csv to table flights\n",
      "Wrote flight_data_2007-10.csv to ../data/interim/\n",
      "Added flight_data_2007-11.csv to table flights\n",
      "Wrote flight_data_2007-11.csv to ../data/interim/\n",
      "Added flight_data_2007-12.csv to table flights\n",
      "Wrote flight_data_2007-12.csv to ../data/interim/\n",
      "Added flight_data_2007-2.csv to table flights\n",
      "Wrote flight_data_2007-2.csv to ../data/interim/\n",
      "Added flight_data_2007-3.csv to table flights\n",
      "Wrote flight_data_2007-3.csv to ../data/interim/\n",
      "Added flight_data_2007-4.csv to table flights\n",
      "Wrote flight_data_2007-4.csv to ../data/interim/\n",
      "Added flight_data_2007-5.csv to table flights\n",
      "Wrote flight_data_2007-5.csv to ../data/interim/\n",
      "Added flight_data_2007-6.csv to table flights\n",
      "Wrote flight_data_2007-6.csv to ../data/interim/\n",
      "Added flight_data_2007-7.csv to table flights\n",
      "Wrote flight_data_2007-7.csv to ../data/interim/\n",
      "Added flight_data_2007-8.csv to table flights\n",
      "Wrote flight_data_2007-8.csv to ../data/interim/\n",
      "Added flight_data_2007-9.csv to table flights\n",
      "Wrote flight_data_2007-9.csv to ../data/interim/\n",
      "Added flight_data_2008-1.csv to table flights\n",
      "Wrote flight_data_2008-1.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2008-10.csv to table flights\n",
      "Wrote flight_data_2008-10.csv to ../data/interim/\n",
      "Added flight_data_2008-11.csv to table flights\n",
      "Wrote flight_data_2008-11.csv to ../data/interim/\n",
      "Added flight_data_2008-12.csv to table flights\n",
      "Wrote flight_data_2008-12.csv to ../data/interim/\n",
      "Added flight_data_2008-2.csv to table flights\n",
      "Wrote flight_data_2008-2.csv to ../data/interim/\n",
      "Added flight_data_2008-3.csv to table flights\n",
      "Wrote flight_data_2008-3.csv to ../data/interim/\n",
      "Added flight_data_2008-4.csv to table flights\n",
      "Wrote flight_data_2008-4.csv to ../data/interim/\n",
      "Added flight_data_2008-5.csv to table flights\n",
      "Wrote flight_data_2008-5.csv to ../data/interim/\n",
      "Added flight_data_2008-6.csv to table flights\n",
      "Wrote flight_data_2008-6.csv to ../data/interim/\n",
      "Added flight_data_2008-7.csv to table flights\n",
      "Wrote flight_data_2008-7.csv to ../data/interim/\n",
      "Added flight_data_2008-8.csv to table flights\n",
      "Wrote flight_data_2008-8.csv to ../data/interim/\n",
      "Added flight_data_2008-9.csv to table flights\n",
      "Wrote flight_data_2008-9.csv to ../data/interim/\n",
      "Added flight_data_2009-1.csv to table flights\n",
      "Wrote flight_data_2009-1.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2009-10.csv to table flights\n",
      "Wrote flight_data_2009-10.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (48,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2009-11.csv to table flights\n",
      "Wrote flight_data_2009-11.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2009-12.csv to table flights\n",
      "Wrote flight_data_2009-12.csv to ../data/interim/\n",
      "Added flight_data_2009-2.csv to table flights\n",
      "Wrote flight_data_2009-2.csv to ../data/interim/\n",
      "Added flight_data_2009-3.csv to table flights\n",
      "Wrote flight_data_2009-3.csv to ../data/interim/\n",
      "Added flight_data_2009-4.csv to table flights\n",
      "Wrote flight_data_2009-4.csv to ../data/interim/\n",
      "Added flight_data_2009-5.csv to table flights\n",
      "Wrote flight_data_2009-5.csv to ../data/interim/\n",
      "Added flight_data_2009-6.csv to table flights\n",
      "Wrote flight_data_2009-6.csv to ../data/interim/\n",
      "Added flight_data_2009-7.csv to table flights\n",
      "Wrote flight_data_2009-7.csv to ../data/interim/\n",
      "Added flight_data_2009-8.csv to table flights\n",
      "Wrote flight_data_2009-8.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2009-9.csv to table flights\n",
      "Wrote flight_data_2009-9.csv to ../data/interim/\n",
      "Added flight_data_2010-1.csv to table flights\n",
      "Wrote flight_data_2010-1.csv to ../data/interim/\n",
      "Added flight_data_2010-10.csv to table flights\n",
      "Wrote flight_data_2010-10.csv to ../data/interim/\n",
      "Added flight_data_2010-11.csv to table flights\n",
      "Wrote flight_data_2010-11.csv to ../data/interim/\n",
      "Added flight_data_2010-12.csv to table flights\n",
      "Wrote flight_data_2010-12.csv to ../data/interim/\n",
      "Added flight_data_2010-2.csv to table flights\n",
      "Wrote flight_data_2010-2.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2010-3.csv to table flights\n",
      "Wrote flight_data_2010-3.csv to ../data/interim/\n",
      "Added flight_data_2010-4.csv to table flights\n",
      "Wrote flight_data_2010-4.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (69,76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2010-5.csv to table flights\n",
      "Wrote flight_data_2010-5.csv to ../data/interim/\n",
      "Added flight_data_2010-6.csv to table flights\n",
      "Wrote flight_data_2010-6.csv to ../data/interim/\n",
      "Added flight_data_2010-7.csv to table flights\n",
      "Wrote flight_data_2010-7.csv to ../data/interim/\n",
      "Added flight_data_2010-8.csv to table flights\n",
      "Wrote flight_data_2010-8.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (48,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2010-9.csv to table flights\n",
      "Wrote flight_data_2010-9.csv to ../data/interim/\n",
      "Added flight_data_2011-1.csv to table flights\n",
      "Wrote flight_data_2011-1.csv to ../data/interim/\n",
      "Added flight_data_2011-10.csv to table flights\n",
      "Wrote flight_data_2011-10.csv to ../data/interim/\n",
      "Added flight_data_2011-11.csv to table flights\n",
      "Wrote flight_data_2011-11.csv to ../data/interim/\n",
      "Added flight_data_2011-12.csv to table flights\n",
      "Wrote flight_data_2011-12.csv to ../data/interim/\n",
      "Added flight_data_2011-2.csv to table flights\n",
      "Wrote flight_data_2011-2.csv to ../data/interim/\n",
      "Added flight_data_2011-3.csv to table flights\n",
      "Wrote flight_data_2011-3.csv to ../data/interim/\n",
      "Added flight_data_2011-4.csv to table flights\n",
      "Wrote flight_data_2011-4.csv to ../data/interim/\n",
      "Added flight_data_2011-5.csv to table flights\n",
      "Wrote flight_data_2011-5.csv to ../data/interim/\n",
      "Added flight_data_2011-6.csv to table flights\n",
      "Wrote flight_data_2011-6.csv to ../data/interim/\n",
      "Added flight_data_2011-7.csv to table flights\n",
      "Wrote flight_data_2011-7.csv to ../data/interim/\n",
      "Added flight_data_2011-8.csv to table flights\n",
      "Wrote flight_data_2011-8.csv to ../data/interim/\n",
      "Added flight_data_2011-9.csv to table flights\n",
      "Wrote flight_data_2011-9.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2012-1.csv to table flights\n",
      "Wrote flight_data_2012-1.csv to ../data/interim/\n",
      "Added flight_data_2012-10.csv to table flights\n",
      "Wrote flight_data_2012-10.csv to ../data/interim/\n",
      "Added flight_data_2012-11.csv to table flights\n",
      "Wrote flight_data_2012-11.csv to ../data/interim/\n",
      "Added flight_data_2012-12.csv to table flights\n",
      "Wrote flight_data_2012-12.csv to ../data/interim/\n",
      "Added flight_data_2012-2.csv to table flights\n",
      "Wrote flight_data_2012-2.csv to ../data/interim/\n",
      "Added flight_data_2012-3.csv to table flights\n",
      "Wrote flight_data_2012-3.csv to ../data/interim/\n",
      "Added flight_data_2012-4.csv to table flights\n",
      "Wrote flight_data_2012-4.csv to ../data/interim/\n",
      "Added flight_data_2012-5.csv to table flights\n",
      "Wrote flight_data_2012-5.csv to ../data/interim/\n",
      "Added flight_data_2012-6.csv to table flights\n",
      "Wrote flight_data_2012-6.csv to ../data/interim/\n",
      "Added flight_data_2012-7.csv to table flights\n",
      "Wrote flight_data_2012-7.csv to ../data/interim/\n",
      "Added flight_data_2012-8.csv to table flights\n",
      "Wrote flight_data_2012-8.csv to ../data/interim/\n",
      "Added flight_data_2012-9.csv to table flights\n",
      "Wrote flight_data_2012-9.csv to ../data/interim/\n",
      "Added flight_data_2013-1.csv to table flights\n",
      "Wrote flight_data_2013-1.csv to ../data/interim/\n",
      "Added flight_data_2013-10.csv to table flights\n",
      "Wrote flight_data_2013-10.csv to ../data/interim/\n",
      "Added flight_data_2013-11.csv to table flights\n",
      "Wrote flight_data_2013-11.csv to ../data/interim/\n",
      "Added flight_data_2013-12.csv to table flights\n",
      "Wrote flight_data_2013-12.csv to ../data/interim/\n",
      "Added flight_data_2013-2.csv to table flights\n",
      "Wrote flight_data_2013-2.csv to ../data/interim/\n",
      "Added flight_data_2013-3.csv to table flights\n",
      "Wrote flight_data_2013-3.csv to ../data/interim/\n",
      "Added flight_data_2013-4.csv to table flights\n",
      "Wrote flight_data_2013-4.csv to ../data/interim/\n",
      "Added flight_data_2013-5.csv to table flights\n",
      "Wrote flight_data_2013-5.csv to ../data/interim/\n",
      "Added flight_data_2013-6.csv to table flights\n",
      "Wrote flight_data_2013-6.csv to ../data/interim/\n",
      "Added flight_data_2013-7.csv to table flights\n",
      "Wrote flight_data_2013-7.csv to ../data/interim/\n",
      "Added flight_data_2013-8.csv to table flights\n",
      "Wrote flight_data_2013-8.csv to ../data/interim/\n",
      "Added flight_data_2013-9.csv to table flights\n",
      "Wrote flight_data_2013-9.csv to ../data/interim/\n",
      "Added flight_data_2014-1.csv to table flights\n",
      "Wrote flight_data_2014-1.csv to ../data/interim/\n",
      "Added flight_data_2014-10.csv to table flights\n",
      "Wrote flight_data_2014-10.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (48,69,76,77,84) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2014-11.csv to table flights\n",
      "Wrote flight_data_2014-11.csv to ../data/interim/\n",
      "Added flight_data_2014-12.csv to table flights\n",
      "Wrote flight_data_2014-12.csv to ../data/interim/\n",
      "Added flight_data_2014-2.csv to table flights\n",
      "Wrote flight_data_2014-2.csv to ../data/interim/\n",
      "Added flight_data_2014-3.csv to table flights\n",
      "Wrote flight_data_2014-3.csv to ../data/interim/\n",
      "Added flight_data_2014-4.csv to table flights\n",
      "Wrote flight_data_2014-4.csv to ../data/interim/\n",
      "Added flight_data_2014-5.csv to table flights\n",
      "Wrote flight_data_2014-5.csv to ../data/interim/\n",
      "Added flight_data_2014-6.csv to table flights\n",
      "Wrote flight_data_2014-6.csv to ../data/interim/\n",
      "Added flight_data_2014-7.csv to table flights\n",
      "Wrote flight_data_2014-7.csv to ../data/interim/\n",
      "Added flight_data_2014-8.csv to table flights\n",
      "Wrote flight_data_2014-8.csv to ../data/interim/\n",
      "Added flight_data_2014-9.csv to table flights\n",
      "Wrote flight_data_2014-9.csv to ../data/interim/\n",
      "Added flight_data_2015-1.csv to table flights\n",
      "Wrote flight_data_2015-1.csv to ../data/interim/\n",
      "Added flight_data_2015-10.csv to table flights\n",
      "Wrote flight_data_2015-10.csv to ../data/interim/\n",
      "Added flight_data_2015-11.csv to table flights\n",
      "Wrote flight_data_2015-11.csv to ../data/interim/\n",
      "Added flight_data_2015-12.csv to table flights\n",
      "Wrote flight_data_2015-12.csv to ../data/interim/\n",
      "Added flight_data_2015-2.csv to table flights\n",
      "Wrote flight_data_2015-2.csv to ../data/interim/\n",
      "Added flight_data_2015-3.csv to table flights\n",
      "Wrote flight_data_2015-3.csv to ../data/interim/\n",
      "Added flight_data_2015-4.csv to table flights\n",
      "Wrote flight_data_2015-4.csv to ../data/interim/\n",
      "Added flight_data_2015-5.csv to table flights\n",
      "Wrote flight_data_2015-5.csv to ../data/interim/\n",
      "Added flight_data_2015-6.csv to table flights\n",
      "Wrote flight_data_2015-6.csv to ../data/interim/\n",
      "Added flight_data_2015-7.csv to table flights\n",
      "Wrote flight_data_2015-7.csv to ../data/interim/\n",
      "Added flight_data_2015-8.csv to table flights\n",
      "Wrote flight_data_2015-8.csv to ../data/interim/\n",
      "Added flight_data_2015-9.csv to table flights\n",
      "Wrote flight_data_2015-9.csv to ../data/interim/\n",
      "Added flight_data_2016-1.csv to table flights\n",
      "Wrote flight_data_2016-1.csv to ../data/interim/\n",
      "Added flight_data_2016-10.csv to table flights\n",
      "Wrote flight_data_2016-10.csv to ../data/interim/\n",
      "Added flight_data_2016-11.csv to table flights\n",
      "Wrote flight_data_2016-11.csv to ../data/interim/\n",
      "Added flight_data_2016-12.csv to table flights\n",
      "Wrote flight_data_2016-12.csv to ../data/interim/\n",
      "Added flight_data_2016-2.csv to table flights\n",
      "Wrote flight_data_2016-2.csv to ../data/interim/\n",
      "Added flight_data_2016-3.csv to table flights\n",
      "Wrote flight_data_2016-3.csv to ../data/interim/\n",
      "Added flight_data_2016-4.csv to table flights\n",
      "Wrote flight_data_2016-4.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (48,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2016-5.csv to table flights\n",
      "Wrote flight_data_2016-5.csv to ../data/interim/\n",
      "Added flight_data_2016-6.csv to table flights\n",
      "Wrote flight_data_2016-6.csv to ../data/interim/\n",
      "Added flight_data_2016-7.csv to table flights\n",
      "Wrote flight_data_2016-7.csv to ../data/interim/\n",
      "Added flight_data_2016-8.csv to table flights\n",
      "Wrote flight_data_2016-8.csv to ../data/interim/\n",
      "Added flight_data_2016-9.csv to table flights\n",
      "Wrote flight_data_2016-9.csv to ../data/interim/\n",
      "Added flight_data_2017-1.csv to table flights\n",
      "Wrote flight_data_2017-1.csv to ../data/interim/\n",
      "Added flight_data_2017-10.csv to table flights\n",
      "Wrote flight_data_2017-10.csv to ../data/interim/\n",
      "Added flight_data_2017-11.csv to table flights\n",
      "Wrote flight_data_2017-11.csv to ../data/interim/\n",
      "Added flight_data_2017-12.csv to table flights\n",
      "Wrote flight_data_2017-12.csv to ../data/interim/\n",
      "Added flight_data_2017-2.csv to table flights\n",
      "Wrote flight_data_2017-2.csv to ../data/interim/\n",
      "Added flight_data_2017-3.csv to table flights\n",
      "Wrote flight_data_2017-3.csv to ../data/interim/\n",
      "Added flight_data_2017-4.csv to table flights\n",
      "Wrote flight_data_2017-4.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (48,77) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2017-5.csv to table flights\n",
      "Wrote flight_data_2017-5.csv to ../data/interim/\n",
      "Added flight_data_2017-6.csv to table flights\n",
      "Wrote flight_data_2017-6.csv to ../data/interim/\n",
      "Added flight_data_2017-7.csv to table flights\n",
      "Wrote flight_data_2017-7.csv to ../data/interim/\n",
      "Added flight_data_2017-8.csv to table flights\n",
      "Wrote flight_data_2017-8.csv to ../data/interim/\n",
      "Added flight_data_2017-9.csv to table flights\n",
      "Wrote flight_data_2017-9.csv to ../data/interim/\n",
      "Added flight_data_2018-1.csv to table flights\n",
      "Wrote flight_data_2018-1.csv to ../data/interim/\n",
      "Added flight_data_2018-10.csv to table flights\n",
      "Wrote flight_data_2018-10.csv to ../data/interim/\n",
      "Added flight_data_2018-11.csv to table flights\n",
      "Wrote flight_data_2018-11.csv to ../data/interim/\n",
      "Added flight_data_2018-12.csv to table flights\n",
      "Wrote flight_data_2018-12.csv to ../data/interim/\n",
      "Added flight_data_2018-2.csv to table flights\n",
      "Wrote flight_data_2018-2.csv to ../data/interim/\n",
      "Added flight_data_2018-3.csv to table flights\n",
      "Wrote flight_data_2018-3.csv to ../data/interim/\n",
      "Added flight_data_2018-4.csv to table flights\n",
      "Wrote flight_data_2018-4.csv to ../data/interim/\n",
      "Added flight_data_2018-5.csv to table flights\n",
      "Wrote flight_data_2018-5.csv to ../data/interim/\n",
      "Added flight_data_2018-6.csv to table flights\n",
      "Wrote flight_data_2018-6.csv to ../data/interim/\n",
      "Added flight_data_2018-7.csv to table flights\n",
      "Wrote flight_data_2018-7.csv to ../data/interim/\n",
      "Added flight_data_2018-8.csv to table flights\n",
      "Wrote flight_data_2018-8.csv to ../data/interim/\n",
      "Added flight_data_2018-9.csv to table flights\n",
      "Wrote flight_data_2018-9.csv to ../data/interim/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/ipykernel_launcher.py:1: DtypeWarning: Columns (48,69,76,77,84,85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added flight_data_2019-1.csv to table flights\n",
      "Wrote flight_data_2019-1.csv to ../data/interim/\n",
      "Added flight_data_2019-2.csv to table flights\n",
      "Wrote flight_data_2019-2.csv to ../data/interim/\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data\n",
    "\n",
    "*Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense.*\n",
    "\n",
    "*Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/visualization/visualize.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed')\n",
    "    # describe_features(data, 'reports/')\n",
    "    # generate_charts(data, 'reports/figures/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What did you learn? What relationships do you think will be most helpful as you build your model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "*Describe the algorithm or algorithms that you plan to use to train with your data. How do these algorithms work? Why are they good choices for this data and problem space?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/train_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed/')\n",
    "    # train, test = train_test_split(data)\n",
    "    # save_train_test(train, test, 'data/processed/')\n",
    "    # model = build_model()\n",
    "    # model.fit(train)\n",
    "    # save_model(model, 'models/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/predict_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # test_X, test_y = load_test_data('data/processed')\n",
    "    # trained_model = load_model('models/')\n",
    "    # predictions = trained_model.predict(test_X)\n",
    "    # metrics = evaluate(test_y, predictions)\n",
    "    # save_metrics('reports/')\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project3)",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257.778px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
