{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "## Overview\n",
    "\n",
    "In February of 2019, tens of thousands of domestic flights carried passengers around the country—every single day. Tens of thousands of aircraft being carefully tracked, monitored, organized and directed, and hundred of thousands or even millions of passengers count on those planes to get them where they're going. It's an incredible system, and most of the time it actually works. But when it doesn't, it hurts. Flight cancellations are extremely expensive, costing airlines a $1 billion per year. While flight cancellations due to weather may be inevitable, a significant portion of cancellations are due to circumstances under _our_ control. Modern air traffic control is a hundred years in the making and has certainly worked to minimize this issue already, but…can we do better?\n",
    "\n",
    "## Question\n",
    "\n",
    "Using data on American commercial flights, can we predict when a cancellation is likely to occur? As a bonus, can we predict _why_ the cancellation will occur?\n",
    "\n",
    "\n",
    "*This is your space to describe your intentions for the project, before writing a single line of code. What are you studying? What are you hoping to build? If you can't explain that clearly before you start digging into the data, you're going to have a hard time planning where to go with this.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data\n",
    "\n",
    "*Describe your data sources here and explain why they are relevant to the problem you are trying to solve.*\n",
    "\n",
    "*Your code should download the data and save it in data/raw. If you've got the data from an offline source, describe where it came from and what the files look like. Don't do anything to the raw data files just yet; that comes in the next step.*\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "My data set will be primarily based around the \"[Marketing Carrier On-Time Performance](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&DB_URL=)\" report released by the Bureau of Transportation Statistics. This database contains information on nearly every flight conducted by a significant U.S. carrier dating back to January 2018, which amounts to approximately 8 million observations. I expect I will supplement this dataset with additional features such as weather forecasts preceding a flight and additional statistics surrounding the model of plane for each flight.\n",
    "\n",
    "*After completing this step, be sure to edit `references/data_dictionary` to include descriptions of where you obtained your data and what information it contains.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/data/make_dataset.py\n",
    "\n",
    "# Imports\n",
    "from io import BytesIO\n",
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "\n",
    "def get_lookup_tables():\n",
    "    # Reporting carrier lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS'\n",
    "    # Reporting airline lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRLINE_ID'\n",
    "    # Airport ID lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT_ID'\n",
    "    # City Market ID lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_CITY_MARKET_ID'\n",
    "    # Airport lookup table (SEA -> Seattle-Tacoma International)\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT'\n",
    "    \n",
    "    lookups = [\n",
    "        'L_UNIQUE_CARRIERS',\n",
    "        'L_AIRLINE_ID',\n",
    "        'L_AIRPORT_ID',\n",
    "        'L_CITY_MARKET_ID',\n",
    "        'L_AIRPORT',\n",
    "        'L_AIRPORT_ID',\n",
    "        'L_CITY_MARKET_ID'\n",
    "    ]\n",
    "    lookup_base = 'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup='\n",
    "    for table in lookups:\n",
    "        download_lookup(lookup_base + table)\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_weather_forecasts():\n",
    "    # Weather forecast API\n",
    "    'https://darksky.net/dev/docs#time-machine-request'\n",
    "    key = 'c00a48b4e746f7a6b5a4caef59e18dc9'\n",
    "    # Example\n",
    "    request_format = f'''\n",
    "    https://api.darksky.net/forecast/{key}/{latitude},{longitude},{time}\n",
    "    '''\n",
    "    example = '''\n",
    "    https://api.darksky.net/forecast/0123456789abcdef9876543210fedcba/\n",
    "    42.3601,-71.0589,255657600?exclude=currently,flags\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def download_dataset(url, path, filename, overwrite='ask'):\n",
    "    \"\"\"\n",
    "    Downloads zip file from specified url and extracts csv file to raw data \n",
    "    directory\n",
    "    Input: \n",
    "        url: string of url from which to retrieve data\n",
    "        path: string of directory path to store file in\n",
    "        filename: string of desired filename\n",
    "        overwrite: parameter for whether or not to overwrite existing files, if\n",
    "            found. If 'y', any existing file with filename in path will be\n",
    "            overwritten. If 'n', function will do nothing. If 'ask', function\n",
    "            will prompt user to decide whether or not to replace file.\n",
    "    Output: dataset stored in raw data directory\n",
    "    \"\"\"\n",
    "    filepath = path + filename\n",
    "    file_exists = os.path.isfile(filepath)\n",
    "    if file_exists:\n",
    "        if overwrite == 'ask':\n",
    "            overwrite = input(f'{filename} already exists. Update? y/n: ')\n",
    "        if overwrite.lower() != 'y':\n",
    "            return\n",
    "                              \n",
    "    print(f'Beginning download of {filename}...')\n",
    "    try:\n",
    "        zip_f = urllib.request.urlopen(url)\n",
    "        with ZipFile(BytesIO(zip_f.read())) as my_zip_file:\n",
    "            for f in my_zip_file.namelist():\n",
    "                if '.csv' in f:\n",
    "                    with open(filepath, 'wb') as output:\n",
    "                        for line in my_zip_file.open(f).readlines():\n",
    "                            output.write(line)\n",
    "        print(f'Successfully wrote {filename} to {path}')\n",
    "                              \n",
    "    except urllib.request.HTTPError:\n",
    "        print(f'Failed to download {filename}')\n",
    "        return\n",
    "\n",
    "\n",
    "def get_flight_data_url(year, month):\n",
    "    '''\n",
    "    Generate URL to download pre-zipped csv of flight data for a given month as\n",
    "    provided by the Bureau of Transportation Statistics\n",
    "    Input: Year in format YYYY (int), Month in format of (M)M, i.e. 3, or 11\n",
    "    Output: download URL as a string\n",
    "    '''\n",
    "    base_url = 'http://transtats.bts.gov/PREZIP/'\n",
    "    tail = 'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_'\n",
    "    slug = f'{year}_{month}.zip'\n",
    "    return base_url + tail + slug\n",
    "    \n",
    "\n",
    "def get_flight_data(start, end, path):\n",
    "    '''\n",
    "    Downloads a variety of flight data tables from:\n",
    "    https://www.transtats.bts.gov/Fields.asp\n",
    "    '''\n",
    "    # Download all BTS datasets\n",
    "    for year in range(start, end):\n",
    "        for month in range(1,13):\n",
    "            filename = f'flight_data_{year}-{month}.csv'\n",
    "            url = get_flight_data_url(year, month)\n",
    "            download_dataset(url, path, filename)\n",
    "    pass\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that download data from one or more sources\n",
    "    and saves those datasets to the data/raw directory.\n",
    "    \"\"\"\n",
    "    path = '../data/raw/'\n",
    "    get_flight_data(2003, 2020, path)\n",
    "    # download_dataset_1(url)\n",
    "    # download_dataset_2(url)\n",
    "    # save_dataset_1('data/raw', filename)\n",
    "    # save_dataset_2('data/raw', filename)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning download of flight_data_2003-1.csv...\n",
      "Successfully wrote flight_data_2003-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-2.csv...\n",
      "Successfully wrote flight_data_2003-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-3.csv...\n",
      "Successfully wrote flight_data_2003-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-4.csv...\n",
      "Successfully wrote flight_data_2003-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-5.csv...\n",
      "Successfully wrote flight_data_2003-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-6.csv...\n",
      "Successfully wrote flight_data_2003-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-7.csv...\n",
      "Successfully wrote flight_data_2003-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-8.csv...\n",
      "Successfully wrote flight_data_2003-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-9.csv...\n",
      "Successfully wrote flight_data_2003-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-10.csv...\n",
      "Successfully wrote flight_data_2003-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-11.csv...\n",
      "Successfully wrote flight_data_2003-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2003-12.csv...\n",
      "Successfully wrote flight_data_2003-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2004-6.csv...\n",
      "Successfully wrote flight_data_2004-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2004-7.csv...\n",
      "Successfully wrote flight_data_2004-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2004-8.csv...\n",
      "Successfully wrote flight_data_2004-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2004-9.csv...\n",
      "Successfully wrote flight_data_2004-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2004-10.csv...\n",
      "Successfully wrote flight_data_2004-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2004-11.csv...\n",
      "Successfully wrote flight_data_2004-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2004-12.csv...\n",
      "Successfully wrote flight_data_2004-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-1.csv...\n",
      "Successfully wrote flight_data_2005-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-2.csv...\n",
      "Successfully wrote flight_data_2005-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-3.csv...\n",
      "Successfully wrote flight_data_2005-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-4.csv...\n",
      "Successfully wrote flight_data_2005-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-5.csv...\n",
      "Successfully wrote flight_data_2005-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-6.csv...\n",
      "Successfully wrote flight_data_2005-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-7.csv...\n",
      "Successfully wrote flight_data_2005-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-8.csv...\n",
      "Successfully wrote flight_data_2005-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-9.csv...\n",
      "Successfully wrote flight_data_2005-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-10.csv...\n",
      "Successfully wrote flight_data_2005-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-11.csv...\n",
      "Successfully wrote flight_data_2005-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2005-12.csv...\n",
      "Successfully wrote flight_data_2005-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-1.csv...\n",
      "Successfully wrote flight_data_2006-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-2.csv...\n",
      "Successfully wrote flight_data_2006-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-3.csv...\n",
      "Successfully wrote flight_data_2006-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-4.csv...\n",
      "Successfully wrote flight_data_2006-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-5.csv...\n",
      "Successfully wrote flight_data_2006-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-6.csv...\n",
      "Successfully wrote flight_data_2006-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-7.csv...\n",
      "Successfully wrote flight_data_2006-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-8.csv...\n",
      "Successfully wrote flight_data_2006-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-9.csv...\n",
      "Successfully wrote flight_data_2006-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-10.csv...\n",
      "Successfully wrote flight_data_2006-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-11.csv...\n",
      "Successfully wrote flight_data_2006-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2006-12.csv...\n",
      "Successfully wrote flight_data_2006-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-1.csv...\n",
      "Successfully wrote flight_data_2007-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-2.csv...\n",
      "Successfully wrote flight_data_2007-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-3.csv...\n",
      "Successfully wrote flight_data_2007-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-4.csv...\n",
      "Successfully wrote flight_data_2007-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-5.csv...\n",
      "Successfully wrote flight_data_2007-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-6.csv...\n",
      "Successfully wrote flight_data_2007-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-7.csv...\n",
      "Successfully wrote flight_data_2007-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-8.csv...\n",
      "Successfully wrote flight_data_2007-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-9.csv...\n",
      "Successfully wrote flight_data_2007-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-10.csv...\n",
      "Successfully wrote flight_data_2007-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-11.csv...\n",
      "Successfully wrote flight_data_2007-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2007-12.csv...\n",
      "Successfully wrote flight_data_2007-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-1.csv...\n",
      "Successfully wrote flight_data_2008-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-2.csv...\n",
      "Successfully wrote flight_data_2008-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-3.csv...\n",
      "Successfully wrote flight_data_2008-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-4.csv...\n",
      "Successfully wrote flight_data_2008-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-5.csv...\n",
      "Successfully wrote flight_data_2008-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-6.csv...\n",
      "Successfully wrote flight_data_2008-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-7.csv...\n",
      "Successfully wrote flight_data_2008-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-8.csv...\n",
      "Successfully wrote flight_data_2008-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-9.csv...\n",
      "Successfully wrote flight_data_2008-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-10.csv...\n",
      "Successfully wrote flight_data_2008-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-11.csv...\n",
      "Successfully wrote flight_data_2008-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2008-12.csv...\n",
      "Successfully wrote flight_data_2008-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-1.csv...\n",
      "Successfully wrote flight_data_2009-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-2.csv...\n",
      "Successfully wrote flight_data_2009-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-3.csv...\n",
      "Successfully wrote flight_data_2009-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-4.csv...\n",
      "Successfully wrote flight_data_2009-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-5.csv...\n",
      "Successfully wrote flight_data_2009-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-6.csv...\n",
      "Successfully wrote flight_data_2009-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-7.csv...\n",
      "Successfully wrote flight_data_2009-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-8.csv...\n",
      "Successfully wrote flight_data_2009-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-9.csv...\n",
      "Successfully wrote flight_data_2009-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-10.csv...\n",
      "Successfully wrote flight_data_2009-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-11.csv...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully wrote flight_data_2009-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2009-12.csv...\n",
      "Successfully wrote flight_data_2009-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-1.csv...\n",
      "Successfully wrote flight_data_2010-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-2.csv...\n",
      "Successfully wrote flight_data_2010-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-3.csv...\n",
      "Successfully wrote flight_data_2010-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-4.csv...\n",
      "Successfully wrote flight_data_2010-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-5.csv...\n",
      "Successfully wrote flight_data_2010-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-6.csv...\n",
      "Successfully wrote flight_data_2010-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-7.csv...\n",
      "Successfully wrote flight_data_2010-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-8.csv...\n",
      "Successfully wrote flight_data_2010-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-9.csv...\n",
      "Successfully wrote flight_data_2010-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-10.csv...\n",
      "Successfully wrote flight_data_2010-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-11.csv...\n",
      "Successfully wrote flight_data_2010-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2010-12.csv...\n",
      "Successfully wrote flight_data_2010-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-1.csv...\n",
      "Successfully wrote flight_data_2011-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-2.csv...\n",
      "Successfully wrote flight_data_2011-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-3.csv...\n",
      "Successfully wrote flight_data_2011-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-4.csv...\n",
      "Successfully wrote flight_data_2011-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-5.csv...\n",
      "Successfully wrote flight_data_2011-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-6.csv...\n",
      "Successfully wrote flight_data_2011-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-7.csv...\n",
      "Successfully wrote flight_data_2011-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-8.csv...\n",
      "Successfully wrote flight_data_2011-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-9.csv...\n",
      "Successfully wrote flight_data_2011-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-10.csv...\n",
      "Successfully wrote flight_data_2011-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-11.csv...\n",
      "Successfully wrote flight_data_2011-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2011-12.csv...\n",
      "Successfully wrote flight_data_2011-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-1.csv...\n",
      "Successfully wrote flight_data_2012-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-2.csv...\n",
      "Successfully wrote flight_data_2012-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-3.csv...\n",
      "Successfully wrote flight_data_2012-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-4.csv...\n",
      "Successfully wrote flight_data_2012-4.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-5.csv...\n",
      "Successfully wrote flight_data_2012-5.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-6.csv...\n",
      "Successfully wrote flight_data_2012-6.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-7.csv...\n",
      "Successfully wrote flight_data_2012-7.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-8.csv...\n",
      "Successfully wrote flight_data_2012-8.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-9.csv...\n",
      "Successfully wrote flight_data_2012-9.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-10.csv...\n",
      "Successfully wrote flight_data_2012-10.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-11.csv...\n",
      "Successfully wrote flight_data_2012-11.csv to ../data/raw/\n",
      "Beginning download of flight_data_2012-12.csv...\n",
      "Successfully wrote flight_data_2012-12.csv to ../data/raw/\n",
      "Beginning download of flight_data_2013-1.csv...\n",
      "Successfully wrote flight_data_2013-1.csv to ../data/raw/\n",
      "Beginning download of flight_data_2013-2.csv...\n",
      "Successfully wrote flight_data_2013-2.csv to ../data/raw/\n",
      "Beginning download of flight_data_2013-3.csv...\n",
      "Successfully wrote flight_data_2013-3.csv to ../data/raw/\n",
      "Beginning download of flight_data_2013-4.csv...\n"
     ]
    }
   ],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/metis/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3049: DtypeWarning: Columns (11,13,57,86,93,94) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/raw/On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(582966, 120)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Year', 'Quarter', 'Month', 'DayofMonth', 'DayOfWeek', 'FlightDate', 'Marketing_Airline_Network', 'Operated_or_Branded_Code_Share_Partners', 'DOT_ID_Marketing_Airline', 'IATA_Code_Marketing_Airline', 'Flight_Number_Marketing_Airline', 'Originally_Scheduled_Code_Share_Airline', 'DOT_ID_Originally_Scheduled_Code_Share_Airline', 'IATA_Code_Originally_Scheduled_Code_Share_Airline', 'Flight_Num_Originally_Scheduled_Code_Share_Airline', 'Operating_Airline ', 'DOT_ID_Operating_Airline', 'IATA_Code_Operating_Airline', 'Tail_Number', 'Flight_Number_Operating_Airline', 'OriginAirportID', 'OriginAirportSeqID', 'OriginCityMarketID', 'Origin', 'OriginCityName', 'OriginState', 'OriginStateFips', 'OriginStateName', 'OriginWac', 'DestAirportID', 'DestAirportSeqID', 'DestCityMarketID', 'Dest', 'DestCityName', 'DestState', 'DestStateFips', 'DestStateName', 'DestWac', 'CRSDepTime', 'DepTime', 'DepDelay', 'DepDelayMinutes', 'DepDel15', 'DepartureDelayGroups', 'DepTimeBlk', 'TaxiOut', 'WheelsOff', 'WheelsOn', 'TaxiIn', 'CRSArrTime', 'ArrTime', 'ArrDelay', 'ArrDelayMinutes', 'ArrDel15', 'ArrivalDelayGroups', 'ArrTimeBlk', 'Cancelled', 'CancellationCode', 'Diverted', 'CRSElapsedTime', 'ActualElapsedTime', 'AirTime', 'Flights', 'Distance', 'DistanceGroup', 'CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay', 'LateAircraftDelay', 'FirstDepTime', 'TotalAddGTime', 'LongestAddGTime', 'DivAirportLandings', 'DivReachedDest', 'DivActualElapsedTime', 'DivArrDelay', 'DivDistance', 'Div1Airport', 'Div1AirportID', 'Div1AirportSeqID', 'Div1WheelsOn', 'Div1TotalGTime', 'Div1LongestGTime', 'Div1WheelsOff', 'Div1TailNum', 'Div2Airport', 'Div2AirportID', 'Div2AirportSeqID', 'Div2WheelsOn', 'Div2TotalGTime', 'Div2LongestGTime', 'Div2WheelsOff', 'Div2TailNum', 'Div3Airport', 'Div3AirportID', 'Div3AirportSeqID', 'Div3WheelsOn', 'Div3TotalGTime', 'Div3LongestGTime', 'Div3WheelsOff', 'Div3TailNum', 'Div4Airport', 'Div4AirportID', 'Div4AirportSeqID', 'Div4WheelsOn', 'Div4TotalGTime', 'Div4LongestGTime', 'Div4WheelsOff', 'Div4TailNum', 'Div5Airport', 'Div5AirportID', 'Div5AirportSeqID', 'Div5WheelsOn', 'Div5TotalGTime', 'Div5LongestGTime', 'Div5WheelsOff', 'Div5TailNum', 'Duplicate', 'Unnamed: 119']\n"
     ]
    }
   ],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    12231\n",
       "A     3631\n",
       "C     2488\n",
       "D        2\n",
       "Name: CancellationCode, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['CancellationCode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>FlightDate</th>\n",
       "      <th>Marketing_Airline_Network</th>\n",
       "      <th>Operated_or_Branded_Code_Share_Partners</th>\n",
       "      <th>DOT_ID_Marketing_Airline</th>\n",
       "      <th>IATA_Code_Marketing_Airline</th>\n",
       "      <th>...</th>\n",
       "      <th>Div5Airport</th>\n",
       "      <th>Div5AirportID</th>\n",
       "      <th>Div5AirportSeqID</th>\n",
       "      <th>Div5WheelsOn</th>\n",
       "      <th>Div5TotalGTime</th>\n",
       "      <th>Div5LongestGTime</th>\n",
       "      <th>Div5WheelsOff</th>\n",
       "      <th>Div5TailNum</th>\n",
       "      <th>Duplicate</th>\n",
       "      <th>Unnamed: 119</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>19805</td>\n",
       "      <td>AA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-02-02</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>19805</td>\n",
       "      <td>AA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-02-03</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>19805</td>\n",
       "      <td>AA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-02-04</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>19805</td>\n",
       "      <td>AA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2019-02-05</td>\n",
       "      <td>AA</td>\n",
       "      <td>AA_CODESHARE</td>\n",
       "      <td>19805</td>\n",
       "      <td>AA</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Quarter  Month  DayofMonth  DayOfWeek  FlightDate  \\\n",
       "0  2019        1      2           1          5  2019-02-01   \n",
       "1  2019        1      2           2          6  2019-02-02   \n",
       "2  2019        1      2           3          7  2019-02-03   \n",
       "3  2019        1      2           4          1  2019-02-04   \n",
       "4  2019        1      2           5          2  2019-02-05   \n",
       "\n",
       "  Marketing_Airline_Network Operated_or_Branded_Code_Share_Partners  \\\n",
       "0                        AA                            AA_CODESHARE   \n",
       "1                        AA                            AA_CODESHARE   \n",
       "2                        AA                            AA_CODESHARE   \n",
       "3                        AA                            AA_CODESHARE   \n",
       "4                        AA                            AA_CODESHARE   \n",
       "\n",
       "   DOT_ID_Marketing_Airline IATA_Code_Marketing_Airline  ...  Div5Airport  \\\n",
       "0                     19805                          AA  ...          NaN   \n",
       "1                     19805                          AA  ...          NaN   \n",
       "2                     19805                          AA  ...          NaN   \n",
       "3                     19805                          AA  ...          NaN   \n",
       "4                     19805                          AA  ...          NaN   \n",
       "\n",
       "  Div5AirportID  Div5AirportSeqID Div5WheelsOn  Div5TotalGTime  \\\n",
       "0           NaN               NaN          NaN             NaN   \n",
       "1           NaN               NaN          NaN             NaN   \n",
       "2           NaN               NaN          NaN             NaN   \n",
       "3           NaN               NaN          NaN             NaN   \n",
       "4           NaN               NaN          NaN             NaN   \n",
       "\n",
       "  Div5LongestGTime  Div5WheelsOff Div5TailNum Duplicate  Unnamed: 119  \n",
       "0              NaN            NaN         NaN         N           NaN  \n",
       "1              NaN            NaN         NaN         N           NaN  \n",
       "2              NaN            NaN         NaN         N           NaN  \n",
       "3              NaN            NaN         NaN         N           NaN  \n",
       "4              NaN            NaN         NaN         N           NaN  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20820.214285714286"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(df['DayofMonth'].value_counts()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DayofMonth  Cancelled\n",
       "1           0.0          21364\n",
       "            1.0            524\n",
       "2           0.0          16021\n",
       "            1.0            376\n",
       "3           0.0          18080\n",
       "            1.0            386\n",
       "4           0.0          21409\n",
       "            1.0            410\n",
       "5           0.0          19852\n",
       "            1.0            566\n",
       "6           0.0          20474\n",
       "            1.0            437\n",
       "7           0.0          21159\n",
       "            1.0            651\n",
       "8           0.0          21491\n",
       "            1.0            405\n",
       "9           0.0          16432\n",
       "            1.0            309\n",
       "10          0.0          19780\n",
       "            1.0            560\n",
       "11          0.0          20785\n",
       "            1.0           1044\n",
       "12          0.0          18289\n",
       "            1.0           2171\n",
       "13          0.0          20413\n",
       "            1.0            699\n",
       "14          0.0          21912\n",
       "            1.0            388\n",
       "15          0.0          22217\n",
       "            1.0            254\n",
       "16          0.0          17289\n",
       "            1.0            119\n",
       "17          0.0          18682\n",
       "            1.0            792\n",
       "18          0.0          21763\n",
       "            1.0            395\n",
       "19          0.0          21196\n",
       "            1.0            388\n",
       "20          0.0          19688\n",
       "            1.0           2210\n",
       "21          0.0          21596\n",
       "            1.0            779\n",
       "22          0.0          22032\n",
       "            1.0            401\n",
       "23          0.0          17392\n",
       "            1.0            480\n",
       "24          0.0          20010\n",
       "            1.0           1083\n",
       "25          0.0          21158\n",
       "            1.0           1231\n",
       "26          0.0          21016\n",
       "            1.0            583\n",
       "27          0.0          20989\n",
       "            1.0            399\n",
       "28          0.0          22125\n",
       "            1.0            312\n",
       "Name: Cancelled, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('DayofMonth')['Cancelled'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub the Data\n",
    "\n",
    "*Look through the raw data files and see what you will need to do to them in order to have a workable data set. If your source data is already well-formatted, you may want to ask yourself why it hasn't already been analyzed and what other people may have overlooked when they were working on it. Are there other data sources that might give you more insights on some of the data you have here?*\n",
    "\n",
    "*The end goal of this step is to produce a [design matrix](https://en.wikipedia.org/wiki/Design_matrix), containing one column for every variable that you are modeling, including a column for the outputs, and one row for every observation in your data set. It needs to be in a format that won't cause any problems as you visualize and model your data.*\n",
    "\n",
    "## Features\n",
    "The following is a list of features I'd like to have in the design matrix:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/features/build_features.py\n",
    "\n",
    "# Imports\n",
    "from os import listdir\n",
    "from psycopg2 import connect\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def run_query(q):\n",
    "    # opens a connection to database to run a query, q\n",
    "    # returns a pandas dataframe\n",
    "    with sqlite3.connect('mlb.db') as conn:\n",
    "        return pd.read_sql(q, conn)\n",
    "\n",
    "    \n",
    "def show_tables():\n",
    "    # Returns a list of all tables and views in our database\n",
    "    q = \"\"\"\n",
    "            SELECT \n",
    "                name, \n",
    "                type \n",
    "            FROM sqlite_master \n",
    "            WHERE type IN (\\\"table\\\",\\\"view\\\");\n",
    "        \"\"\"\n",
    "    return run_query(q)\n",
    "\n",
    "\n",
    "def run_command(q, db='flights'):\n",
    "    # opens a connection to database to run a command with no output\n",
    "    with sqlite3.connect(db) as conn:\n",
    "        conn.execute('PRAGMA foreign_keys = ON;')\n",
    "        conn.isolation_level = None\n",
    "        conn.execute(q)\n",
    "\n",
    "        \n",
    "def check_existence(query, item, cursor):\n",
    "    '''\n",
    "    Executes a query and checks if item is in returned results\n",
    "    Input: \n",
    "        query (str), a SQL query returning list of items to look within\n",
    "        item (str), the name of the item to check if exists\n",
    "        cursor, a psycogp2 cursor object\n",
    "    Output: boolean, True if item exists\n",
    "    '''\n",
    "    cursor.execute(query)\n",
    "    items = [i[0] for i in cursor.fetchall()]\n",
    "    exists = item in items\n",
    "    return exists\n",
    "\n",
    "    \n",
    "def load_table(file, path, params, overwrite='ask'):\n",
    "    ''' \n",
    "    Loads a csv into a SQL table\n",
    "    Input:\n",
    "        file (str), filename of csv to load\n",
    "        path (str), relative directory to find file in\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "            and port\n",
    "        overwrite (str): parameter for whether or not to overwrite existing \n",
    "            files, if found. If 'y', any existing file with filename in path \n",
    "            will be overwritten. If 'n', function will do nothing. If 'ask', \n",
    "            function will prompt user to decide whether or not to replace file.\n",
    "    '''\n",
    "    file_path = path + file\n",
    "    table_name = f'flights_{file[12:-4]}'\n",
    "    \n",
    "    q = \"\"\"\n",
    "    SELECT tablename \n",
    "    FROM pg_catalog.pg_tables \n",
    "    WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with connect(**params) as conn:\n",
    "            conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "            print(f\"Connecting to database {params['dbname']}\")\n",
    "            cur = conn.cursor()\n",
    "            exists = check_existence(q, table_name, cur)\n",
    "            if exists:\n",
    "                if overwrite == 'ask':\n",
    "                    overwrite = input(f'{filename} already exists. Update? y/n: ')\n",
    "                if overwrite.lower() != 'y':\n",
    "                    return\n",
    "            if check_existence(q, table_name, cur):\n",
    "                # Truncate the table first\n",
    "                cur.execute(f'TRUNCATE {table_name} CASCADE;')\n",
    "                print(f'Truncated {table_name}')\n",
    "            with open(file_path, 'r') as f:\n",
    "                c = f'COPY {table_name} FROM STDIN WITH CSV HEADER'\n",
    "                cur.copy_expert(c, f)\n",
    "                print(f'Loaded data into {table_name}')\n",
    "    except Exception as e:\n",
    "        print(f'Error: {str(e)}')\n",
    "        sys.exit(1)\n",
    "    pass\n",
    "\n",
    "        \n",
    "def create_db(dbname, params):\n",
    "    '''\n",
    "    Connects to psql as default user and creates new database if it doesn't\n",
    "    already exist\n",
    "    Input:\n",
    "        dbname (string), name of new database\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "        and port\n",
    "    Output: database created in psql\n",
    "    '''\n",
    "    q = 'SELECT datname FROM pg_database;'\n",
    "    temp_params = params.copy()\n",
    "    temp_params['dbname'] = 'postgres'\n",
    "    with connect(**temp_params) as conn:\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(q)\n",
    "        databases = [db[0] for db in cur.fetchall()]\n",
    "        db_exists = dbname in databases\n",
    "        if not db_exists:\n",
    "            cur.execute(f'CREATE DATABASE {dbname}')\n",
    "            print(f'Created database {dbname}')\n",
    "    pass\n",
    "        \n",
    "\n",
    "def build_raw_database():\n",
    "    '''\n",
    "    Constructs database from raw data CSVs previously downloaded\n",
    "    '''\n",
    "    path = '../data/raw/'\n",
    "    params = {\n",
    "        'user': 'scottbutters',\n",
    "        'host': '127.0.0.1',\n",
    "        'port': 5432,\n",
    "        'dbname': 'raw_flight_data'\n",
    "    }\n",
    "    \n",
    "    # Create db if DNE yet\n",
    "    create_db(dbname=params['dbname'], params=params)\n",
    "    \n",
    "    # Collect list of csvs and load into tables\n",
    "    files = [f for f in listdir(path) if '.csv' in f]\n",
    "    for file in files:\n",
    "        load_table(file, path, params)\n",
    "    \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/raw, cleans them,\n",
    "    and converts the data into a design matrix that is ready for modeling.\n",
    "    \"\"\"\n",
    "    build_raw_database()\n",
    "    build_interim_database()\n",
    "    data = clean_data()\n",
    "    create_\n",
    "    \n",
    "    # clean_dataset_1('data/raw', filename)\n",
    "    # clean_dataset_2('data/raw', filename)\n",
    "    # save_cleaned_data_1('data/interim', filename)\n",
    "    # save_cleaned_data_2('data/interim', filename)\n",
    "    # build_features()\n",
    "    # save_features('data/processed')\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data\n",
    "\n",
    "*Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense.*\n",
    "\n",
    "*Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/visualization/visualize.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed')\n",
    "    # describe_features(data, 'reports/')\n",
    "    # generate_charts(data, 'reports/figures/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What did you learn? What relationships do you think will be most helpful as you build your model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "*Describe the algorithm or algorithms that you plan to use to train with your data. How do these algorithms work? Why are they good choices for this data and problem space?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/train_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed/')\n",
    "    # train, test = train_test_split(data)\n",
    "    # save_train_test(train, test, 'data/processed/')\n",
    "    # model = build_model()\n",
    "    # model.fit(train)\n",
    "    # save_model(model, 'models/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/predict_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # test_X, test_y = load_test_data('data/processed')\n",
    "    # trained_model = load_model('models/')\n",
    "    # predictions = trained_model.predict(test_X)\n",
    "    # metrics = evaluate(test_y, predictions)\n",
    "    # save_metrics('reports/')\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project3)",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "257.778px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
