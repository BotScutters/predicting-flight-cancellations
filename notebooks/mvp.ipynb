{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract\n",
    "\n",
    "## Overview\n",
    "\n",
    "In February of 2019, tens of thousands of domestic flights carried passengers around the country—every single day. Tens of thousands of aircraft being carefully tracked, monitored, organized and directed, and hundred of thousands or even millions of passengers count on those planes to get them where they're going. It's an incredible system, and most of the time it actually works. But when it doesn't, it hurts. Flight cancellations are extremely expensive, costing airlines a $1 billion per year. While flight cancellations due to weather may be inevitable, a significant portion of cancellations are due to circumstances under _our_ control. Modern air traffic control is a hundred years in the making and has certainly worked to minimize this issue already, but…can we do better?\n",
    "\n",
    "## Question\n",
    "\n",
    "Using data on American commercial flights, can we predict when a cancellation is likely to occur? As a bonus, can we predict _why_ the cancellation will occur?\n",
    "\n",
    "\n",
    "*This is your space to describe your intentions for the project, before writing a single line of code. What are you studying? What are you hoping to build? If you can't explain that clearly before you start digging into the data, you're going to have a hard time planning where to go with this.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtain the Data\n",
    "\n",
    "*Describe your data sources here and explain why they are relevant to the problem you are trying to solve.*\n",
    "\n",
    "*Your code should download the data and save it in data/raw. If you've got the data from an offline source, describe where it came from and what the files look like. Don't do anything to the raw data files just yet; that comes in the next step.*\n",
    "\n",
    "## Data Sources\n",
    "\n",
    "My data set will be primarily based around the \"[Marketing Carrier On-Time Performance](https://www.transtats.bts.gov/DatabaseInfo.asp?DB_ID=120&DB_URL=)\" report released by the Bureau of Transportation Statistics. This database contains information on nearly every flight conducted by a significant U.S. carrier dating back to January 2018, which amounts to approximately 8 million observations. I expect I will supplement this dataset with additional features such as weather forecasts preceding a flight and additional statistics surrounding the model of plane for each flight.\n",
    "\n",
    "*After completing this step, be sure to edit `references/data_dictionary` to include descriptions of where you obtained your data and what information it contains.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/data/make_dataset.py\n",
    "\n",
    "# Imports\n",
    "from io import BytesIO\n",
    "import os\n",
    "import urllib.request\n",
    "from zipfile import ZipFile\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "\n",
    "\n",
    "def get_lookup_tables():\n",
    "    # Reporting carrier lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_UNIQUE_CARRIERS'\n",
    "    # Reporting airline lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRLINE_ID'\n",
    "    # Airport ID lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT_ID'\n",
    "    # City Market ID lookup table\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_CITY_MARKET_ID'\n",
    "    # Airport lookup table (SEA -> Seattle-Tacoma International)\n",
    "    'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup=L_AIRPORT'\n",
    "    \n",
    "    lookups = [\n",
    "        'L_UNIQUE_CARRIERS',\n",
    "        'L_AIRLINE_ID',\n",
    "        'L_AIRPORT_ID',\n",
    "        'L_CITY_MARKET_ID',\n",
    "        'L_AIRPORT',\n",
    "        'L_AIRPORT_ID',\n",
    "        'L_CITY_MARKET_ID'\n",
    "    ]\n",
    "    lookup_base = 'https://www.transtats.bts.gov/Download_Lookup.asp?Lookup='\n",
    "    for table in lookups:\n",
    "        download_lookup(lookup_base + table)\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_weather_forecasts():\n",
    "    # Weather forecast API\n",
    "    'https://darksky.net/dev/docs#time-machine-request'\n",
    "    key = 'c00a48b4e746f7a6b5a4caef59e18dc9'\n",
    "    # Example\n",
    "    request_format = f'''\n",
    "    https://api.darksky.net/forecast/{key}/{latitude},{longitude},{time}\n",
    "    '''\n",
    "    example = '''\n",
    "    https://api.darksky.net/forecast/0123456789abcdef9876543210fedcba/\n",
    "    42.3601,-71.0589,255657600?exclude=currently,flags\n",
    "    '''\n",
    "    pass\n",
    "\n",
    "\n",
    "def download_dataset(url, path, filename, overwrite='ask'):\n",
    "    \"\"\"\n",
    "    Downloads zip file from specified url and extracts csv file to raw data \n",
    "    directory\n",
    "    Input: \n",
    "        url: string of url from which to retrieve data\n",
    "        path: string of directory path to store file in\n",
    "        filename: string of desired filename\n",
    "        overwrite: parameter for whether or not to overwrite existing files, if\n",
    "            found. If 'y', any existing file with filename in path will be\n",
    "            overwritten. If 'n', function will do nothing. If 'ask', function\n",
    "            will prompt user to decide whether or not to replace file.\n",
    "    Output: dataset stored in raw data directory\n",
    "    \"\"\"\n",
    "    filepath = path + filename\n",
    "    file_exists = os.path.isfile(filepath)\n",
    "    if file_exists:\n",
    "        if overwrite == 'ask':\n",
    "            overwrite = input(f'{filename} already exists. Update? y/n: ')\n",
    "        if overwrite.lower() != 'y':\n",
    "            return\n",
    "                              \n",
    "    print(f'Beginning download of {filename}...')\n",
    "    try:\n",
    "        zip_f = urllib.request.urlopen(url)\n",
    "        with ZipFile(BytesIO(zip_f.read())) as my_zip_file:\n",
    "            for f in my_zip_file.namelist():\n",
    "                if '.csv' in f:\n",
    "                    with open(filepath, 'wb') as output:\n",
    "                        for line in my_zip_file.open(f).readlines():\n",
    "                            output.write(line)\n",
    "        print(f'Successfully wrote {filename} to {path}')\n",
    "                              \n",
    "    except urllib.request.HTTPError:\n",
    "        print(f'Failed to download {filename}')\n",
    "        return\n",
    "\n",
    "\n",
    "def get_flight_data_url(year, month):\n",
    "    '''\n",
    "    Generate URL to download pre-zipped csv of flight data for a given month as\n",
    "    provided by the Bureau of Transportation Statistics\n",
    "    Input: Year in format YYYY (int), Month in format of (M)M, i.e. 3, or 11\n",
    "    Output: download URL as a string\n",
    "    '''\n",
    "    base_url = 'http://transtats.bts.gov/PREZIP/'\n",
    "    tail = 'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_'\n",
    "    slug = f'{year}_{month}.zip'\n",
    "    return base_url + tail + slug\n",
    "    \n",
    "\n",
    "def get_flight_data(start, end, path):\n",
    "    '''\n",
    "    Downloads a variety of flight data tables from:\n",
    "    https://www.transtats.bts.gov/Fields.asp\n",
    "    '''\n",
    "    # Download all BTS datasets\n",
    "    for year in range(start, end):\n",
    "        for month in range(1,13):\n",
    "            filename = f'flight_data_{year}-{month}.csv'\n",
    "            url = get_flight_data_url(year, month)\n",
    "            download_dataset(url, path, filename)\n",
    "    pass\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that download data from one or more sources\n",
    "    and saves those datasets to the data/raw directory.\n",
    "    \"\"\"\n",
    "    path = '../data/raw/'\n",
    "    get_flight_data(2003, 2020, path)\n",
    "    # download_dataset_1(url)\n",
    "    # download_dataset_2(url)\n",
    "    # save_dataset_1('data/raw', filename)\n",
    "    # save_dataset_2('data/raw', filename)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/raw/On_Time_Marketing_Carrier_On_Time_Performance_(Beginning_January_2018)_2019_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['CancellationCode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(df['DayofMonth'].value_counts()).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('DayofMonth')['Cancelled'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub the Data\n",
    "\n",
    "*Look through the raw data files and see what you will need to do to them in order to have a workable data set. If your source data is already well-formatted, you may want to ask yourself why it hasn't already been analyzed and what other people may have overlooked when they were working on it. Are there other data sources that might give you more insights on some of the data you have here?*\n",
    "\n",
    "*The end goal of this step is to produce a [design matrix](https://en.wikipedia.org/wiki/Design_matrix), containing one column for every variable that you are modeling, including a column for the outputs, and one row for every observation in your data set. It needs to be in a format that won't cause any problems as you visualize and model your data.*\n",
    "\n",
    "## Features\n",
    "The following is a list of features I'd like to have in the design matrix:\n",
    "\n",
    "\n",
    "| Feature                               | Description                                                  | Type        | Purpose |\n",
    "| ------------------------------------- | ------------------------------------------------------------ | ----------- | ------- |\n",
    "| Airline ID                            | ID number to identify unique airline                         | Categorical | Key     |\n",
    "| AL_C_rate_day                         | Flight cancellation rate by this airline at this airport over past 24 hours | Continuous  | Feature |\n",
    "| AL_C_rate_7                           | Flight cancellation rate by this airline on this weekday 1 week ago | Continuous  | Feature |\n",
    "| AL_C_avg_rate_week                    | Flight cancellation rate by this airline at this airport over past 7 days | Continuous  | Feature |\n",
    "| AL_C_rate_28                          | Flight cancellation rate by this airline on this weekday 4 weeks ago | Continuous  | Feature |\n",
    "| AL_C_avg_rate_month                   | Flight cancellation rate by this airline at this airport over past 30 days | Continuous  | Feature |\n",
    "| AL_C_rate_364                         | Flight cancellation rate by this airline on this weekday 52 weeks ago | Continuous  | Feature |\n",
    "| AL_C_avg_rate_year                    | Flight cancellation rate by this airline at this airport over past 365 days | Continuous  | Feature |\n",
    "| Tail number                           | Unique airplane identifier ID                                | Categorical | Key     |\n",
    "| AP_C_rate_day                         | Flight cancellation rate by this airplane over past 24 hours | Continuous  | Feature |\n",
    "| AP_C_rate_7                           | Flight cancellation rate by this airplane on this weekday 1 week ago | Continuous  | Feature |\n",
    "| AP_C_avg_rate_week                    | Flight cancellation rate by this airplane at this airport over past 7 days | Continuous  | Feature |\n",
    "| AP_C_rate_28                          | Flight cancellation rate by this airplane on this weekday 4 weeks ago | Continuous  | Feature |\n",
    "| AP_C_avg_rate_month                   | Flight cancellation rate by this airplane at this airport over past 30 days | Continuous  | Feature |\n",
    "| AP_C_rate_364                         | Flight cancellation rate by this airplane on this weekday 52 weeks ago | Continuous  | Feature |\n",
    "| AP_C_avg_rate_year                    | Flight cancellation rate by this airplane at this airport over past 365 days | Continuous  | Feature |\n",
    "| Origin Airport ID                     | Unique airport identifier ID for flight origin               | Categorical | Key     |\n",
    "| orig_C_rate_day                       | Flight cancellation rate for flights departing from origin airport over past 24 hours | Continuous  | Feature |\n",
    "| repeat same pattern as above          |                                                              |             |         |\n",
    "| Origin City Market                    | ID for area that may be served by several airlines           | Categorical | Key     |\n",
    "| OCM_C_rate_day                        | Flight cancellation rate for flights departing from origin city market over past 24 hours | Continuous  | Feature |\n",
    "| repeat same pattern as above          |                                                              |             |         |\n",
    "| Dest Airport ID                       | Unique airport identifier ID for destination                 | Categorical | Key     |\n",
    "| dest_C_rate_day                       | Flight cancellation rate for flights heading to destination airport over past 24 hours | Continuous  | Feature |\n",
    "| repeat same pattern as above          |                                                              |             |         |\n",
    "| Dest City Market                      | ID for area that may be served by several airlines           | Categorical | Key     |\n",
    "| DCM_C_rate_day                        | Flight cancellation rate for flights heading to destination city market over past 24 hours | Continuous  | Feature |\n",
    "| repeat same pattern as above          |                                                              |             |         |\n",
    "| Departure time                        | Scheduled departure time                                     | ?           |         |\n",
    "| Airtime                               | Planned time in air, in minutes                              | Continuous  |         |\n",
    "| Distance                              | Planned route distance                                       | Continuous  |         |\n",
    "| On-time incoming arrival percentage   | Percent of flights that arrive at departure airport on-time  | Continuous  |         |\n",
    "| On-time outgoing departure percentage | Percent of flights that depart from departure airport on-time | Continuous  |         |\n",
    "| Historical cancellation percentages   | All time average                                             | Continuous  |         |\n",
    "|                                       | 1 day ago                                                    | Continuous  |         |\n",
    "|                                       | 7 days ago                                                   | Continuous  |         |\n",
    "|                                       | 30 days ago                                                  | Continuous  |         |\n",
    "|                                       | 364 days ago                                                 | Continuous  |         |\n",
    "|                                       | For this airline                                             | Continuous  |         |\n",
    "|                                       | From this airport                                            | Continuous  |         |\n",
    "|                                       | To that airport                                              | Continuous  |         |\n",
    "|                                       | On this airplane (tail number)                               | Continuous  |         |\n",
    "|                                       | On this airplane model                                       | Continuous  |         |\n",
    "| Historical delays (goes back to 2003) | The average number of minutes that a similar incoming flight has been delayed (in minutes) over the avove time periods, for the reasons: carrier delay, weather delay, national air system delay, security delay, and late aircraft delay |             |         |\n",
    "|                                       |                                                              |             |         |\n",
    "| Weather Forecast                      | What the weather forecast was ~24 hours ago, in degrees      | Continuous  |         |\n",
    "| Other airline/craft statistics        |                                                              |             |         |\n",
    "| Cancelled                             | Boolean for whether or not flight is cancelled, 1=Yes        | Boolean     |         |\n",
    "| Cancellation Code                     | Reason for cancellation (carrier, weather, national air system, security) | Categorical |         |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile ../src/features/build_features.py\n",
    "\n",
    "# Imports\n",
    "import csv\n",
    "from os import listdir\n",
    "import subprocess\n",
    "import sys\n",
    "from psycopg2 import connect\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def export_design_matrix(df):\n",
    "    \"\"\"\n",
    "    Pickles design matrix and stores in processed directory to be trained on\n",
    "    Input: clean design matrix df containing only features and target\n",
    "    Outpu: pickled design matrix in data directory\n",
    "    \"\"\"\n",
    "    df.to_pickle('../data/processed/data.pkl')\n",
    "    pass\n",
    "\n",
    "\n",
    "def build_features():\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    # Design matrix\n",
    "    dm = \"\"\"\n",
    "    SELECT\n",
    "        CAST(flightdate AS DATE) || '_fl' || flight_number_reporting_airline\n",
    "            AS flight,\n",
    "        crselapsedtime,\n",
    "        distance,\n",
    "        cancelled\n",
    "    FROM flights\n",
    "    WHERE flightdate > '2017-01-01'\n",
    "    ;\"\"\"\n",
    "    df = pd.read_sql(dm, engine, index_col='flight')\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "# Airline cancellation rate\n",
    "def get_avg_cancellation_rate(by, time):\n",
    "    pass\n",
    "\n",
    "\n",
    "def get_past_cancellation_rate(by, time):\n",
    "    pass\n",
    "\n",
    "\n",
    "def run_query(query, params, engine):\n",
    "    '''\n",
    "    Opens a connection to database to run a query, q\n",
    "    Input: \n",
    "        query (str), a SQL command that requests output\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "            and port\n",
    "    Output: a pandas dataframe containing the query output\n",
    "    '''\n",
    "    return pd.read_sql(query, engine)\n",
    "\n",
    "    \n",
    "def show_tables(params):\n",
    "    # Returns a list of all tables and views in our database\n",
    "    q = \"\"\"\n",
    "    SELECT tablename \n",
    "    FROM pg_catalog.pg_tables \n",
    "    WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';\n",
    "    \"\"\"\n",
    "    return run_query(q, params)\n",
    "\n",
    "\n",
    "def run_command(command, params):\n",
    "    '''\n",
    "    Opens a connection to database to run a command with no output\n",
    "    Input: \n",
    "        command (str), a SQL query that commits an action\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "            and port\n",
    "    '''\n",
    "    with connect(**params) as conn:\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute(command)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "def check_table_exists(table, cursor):\n",
    "    '''\n",
    "    Executes a query and checks if item is in returned results\n",
    "    Input: \n",
    "        query (str), a SQL query returning list of items to look within\n",
    "        item (str), the name of the item to check if exists\n",
    "        cursor, a psycogp2 cursor object\n",
    "    Output: boolean, True if item exists\n",
    "    '''\n",
    "    query = \"\"\"\n",
    "    SELECT tablename \n",
    "    FROM pg_catalog.pg_tables \n",
    "    WHERE schemaname != 'pg_catalog' AND schemaname != 'information_schema';\n",
    "    \"\"\"\n",
    "    cursor.execute(query)\n",
    "    items = [i[0] for i in cursor.fetchall()]\n",
    "    print(f'Found tables: {items}')\n",
    "    exists = table in items\n",
    "    return exists\n",
    "\n",
    "\n",
    "def check_db_exists(db, cursor):\n",
    "    '''\n",
    "    Executes a query and checks if item is in returned results\n",
    "    Input: \n",
    "        query (str), a SQL query returning list of items to look within\n",
    "        item (str), the name of the item to check if exists\n",
    "        cursor, a psycogp2 cursor object\n",
    "    Output: boolean, True if item exists\n",
    "    '''\n",
    "    query = 'SELECT datname FROM pg_database;'\n",
    "    cursor.execute(query)\n",
    "    items = [i[0] for i in cursor.fetchall()]\n",
    "    print(f'Found items: {items}')\n",
    "    exists = db in items\n",
    "    return exists\n",
    "                  \n",
    "                  \n",
    "def make_table(path, file, engine, table):\n",
    "    df = pd.read_csv(path + file)\n",
    "\n",
    "    drop_cols = [\n",
    "        'DOT_ID_Reporting_Airline',\n",
    "        'IATA_CODE_Reporting_Airline', \n",
    "        'OriginAirportSeqID', \n",
    "        'OriginStateFips',\n",
    "        'OriginWac',\n",
    "        'DestAirportSeqID', \n",
    "        'DestStateFips',\n",
    "        'DestWac',\n",
    "        'TaxiOut',\n",
    "        'WheelsOff', \n",
    "        'WheelsOn', \n",
    "        'TaxiIn'\n",
    "    ]\n",
    "\n",
    "    short_df = df[df.columns[:61]].drop(drop_cols, axis=1)\n",
    "\n",
    "    shorter_df = short_df[\n",
    "        short_df['Origin'].str.contains('SEA') |\n",
    "        short_df['Dest'].str.contains('SEA')\n",
    "    ]\n",
    "\n",
    "    index = (shorter_df['FlightDate'].astype(str) \n",
    "             + '_' + shorter_df['Flight_Number_Reporting_Airline'].astype(str))\n",
    "\n",
    "    shorter_df.set_index(\n",
    "        keys=index,\n",
    "        inplace=True\n",
    "    )\n",
    "\n",
    "    shorter_df.columns = [col.lower() for col in shorter_df.columns]\n",
    "    \n",
    "    # Define types\n",
    "    types = {\n",
    "        'year': sqlalchemy.types.INTEGER(),\n",
    "        'quarter': sqlalchemy.types.INTEGER(),\n",
    "        'month': sqlalchemy.types.INTEGER(),\n",
    "        'dayofmonth': sqlalchemy.types.INTEGER(),\n",
    "        'dayofweek': sqlalchemy.types.INTEGER(),\n",
    "        'flightdate': sqlalchemy.DateTime(),\n",
    "        'reporting_airline': sqlalchemy.types.VARCHAR(),\n",
    "        'tail_number': sqlalchemy.types.VARCHAR(),\n",
    "        'flight_number_reporting_airline': sqlalchemy.types.VARCHAR(),\n",
    "        'originairportid': sqlalchemy.types.VARCHAR(),\n",
    "        'origincitymarketid': sqlalchemy.types.VARCHAR(),\n",
    "        'origin': sqlalchemy.types.VARCHAR(),\n",
    "        'origincityname': sqlalchemy.types.VARCHAR(),\n",
    "        'originstate': sqlalchemy.types.VARCHAR(),\n",
    "        'originstatename': sqlalchemy.types.VARCHAR(),\n",
    "        'destairportid': sqlalchemy.types.VARCHAR(),\n",
    "        'destcitymarketid': sqlalchemy.types.VARCHAR(),\n",
    "        'dest': sqlalchemy.types.VARCHAR(),\n",
    "        'destcityname': sqlalchemy.types.VARCHAR(),\n",
    "        'deststate': sqlalchemy.types.VARCHAR(),\n",
    "        'deststatename': sqlalchemy.types.VARCHAR(),\n",
    "        'crsdeptime': sqlalchemy.types.INTEGER(),\n",
    "        'deptime': sqlalchemy.types.INTEGER(),\n",
    "        'depdelay': sqlalchemy.types.INTEGER(),\n",
    "        'depdelayminutes': sqlalchemy.types.INTEGER(),\n",
    "        'depdel15': sqlalchemy.types.BOOLEAN(),\n",
    "        'departuredelaygroups': sqlalchemy.types.INTEGER(),\n",
    "        'deptimeblk': sqlalchemy.types.VARCHAR(),\n",
    "        'crsarrtime': sqlalchemy.types.INTEGER(),\n",
    "        'arrtime': sqlalchemy.types.INTEGER(),\n",
    "        'arrdelay': sqlalchemy.types.INTEGER(),\n",
    "        'arrdelayminutes': sqlalchemy.types.INTEGER(),\n",
    "        'arrdel15': sqlalchemy.types.BOOLEAN(),\n",
    "        'arrivaldelaygroups': sqlalchemy.types.INTEGER(),\n",
    "        'arrtimeblk': sqlalchemy.types.VARCHAR(),\n",
    "        'cancelled': sqlalchemy.types.INTEGER(),\n",
    "        'cancellationcode': sqlalchemy.types.VARCHAR(),\n",
    "        'diverted': sqlalchemy.types.VARCHAR(),\n",
    "        'crselapsedtime': sqlalchemy.types.VARCHAR(),\n",
    "        'actualelapsedtime': sqlalchemy.types.INTEGER(),\n",
    "        'airtime': sqlalchemy.types.INTEGER(),\n",
    "        'flights': sqlalchemy.types.INTEGER(),\n",
    "        'distance': sqlalchemy.types.INTEGER(),\n",
    "        'distancegroup': sqlalchemy.types.INTEGER(),\n",
    "        'carrierdelay': sqlalchemy.types.VARCHAR(),\n",
    "        'weatherdelay': sqlalchemy.types.VARCHAR(),\n",
    "        'nasdelay': sqlalchemy.types.VARCHAR(),\n",
    "        'securitydelay': sqlalchemy.types.VARCHAR(),\n",
    "        'lateaircraftdelay': sqlalchemy.types.VARCHAR(),\n",
    "    }\n",
    "                  \n",
    "    # Add to SQL table\n",
    "    shorter_df.to_sql(\n",
    "        table, engine, if_exists='append', dtype=types, index=False)\n",
    "    print(f'Added {file} to table {table}')\n",
    "                  \n",
    "    int_path = '../data/interim/'\n",
    "    shorter_df.to_csv(f'{int_path}reduced_{file}')\n",
    "    print(f'Wrote {file} to {int_path}')\n",
    "    pass\n",
    "\n",
    "                  \n",
    "def create_db(dbname, params):\n",
    "    '''\n",
    "    Connects to psql as default user and creates new database if it doesn't\n",
    "    already exist\n",
    "    Input:\n",
    "        dbname (string), name of new database\n",
    "        params (dict), parameters for connecting to psql, including user, host,\n",
    "        and port\n",
    "    Output: database created in psql\n",
    "    '''\n",
    "    \n",
    "    temp_params = params.copy()\n",
    "    temp_params['dbname'] = 'postgres'\n",
    "    with connect(**temp_params) as conn:\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        cur = conn.cursor()\n",
    "        exists = check_db_exists(dbname, cur)\n",
    "        if not exists:\n",
    "            cur.execute(f'CREATE DATABASE {dbname}')\n",
    "            print(f'Created database {dbname}')\n",
    "    pass\n",
    "        \n",
    "\n",
    "def build_raw_database():\n",
    "    '''\n",
    "    Constructs database from raw data CSVs previously downloaded\n",
    "    '''\n",
    "    path = '../data/raw/'\n",
    "    params = {\n",
    "        'user': 'scottbutters',\n",
    "        'host': '127.0.0.1',\n",
    "        'port': 5432,\n",
    "        'dbname': 'raw_flight_data'\n",
    "    }\n",
    "    table_name = 'flights'\n",
    "    \n",
    "    connection_string = f\"postgresql:///{params['dbname']}\"\n",
    "    engine = create_engine(connection_string)\n",
    "\n",
    "    # Create db if DNE yet\n",
    "    create_db(dbname=params['dbname'], params=params)\n",
    "    \n",
    "    # Check whether table exists and prompt about dropping\n",
    "    with connect(**params) as conn:\n",
    "        conn.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "        print(f\"Connecting to database {params['dbname']}\")\n",
    "        cur = conn.cursor()\n",
    "        exists = check_table_exists(table_name, cur)\n",
    "        if exists:\n",
    "            overwrite = input(f'{table_name} already exists. Update? y/n: ')\n",
    "            if overwrite.lower() != 'y':\n",
    "                return\n",
    "            run_command('DROP TABLE flights;', params)\n",
    "\n",
    "    # Collect list of csvs\n",
    "    files = [f for f in listdir(path) if '.csv' in f]\n",
    "    files = sorted(files)\n",
    "    \n",
    "    # Shrink files and load all into SQL table\n",
    "    for file in files:\n",
    "        make_table(path, file, engine, table_name)\n",
    "    pass\n",
    "        \n",
    "        \n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/raw, cleans them,\n",
    "    and converts the data into a design matrix that is ready for modeling.\n",
    "    \"\"\"\n",
    "    build_raw_database()\n",
    "#     data = clean_data()\n",
    "#     create_\n",
    "    \n",
    "    # clean_dataset_1('data/raw', filename)\n",
    "    # clean_dataset_2('data/raw', filename)\n",
    "    # save_cleaned_data_1('data/interim', filename)\n",
    "    # save_cleaned_data_2('data/interim', filename)\n",
    "    data = build_features()\n",
    "    export_design_matrix(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found items: ['postgres', 'scottbutters', 'template1', 'template0', 'names', 'store', 'raw_flight_data', 'test']\n",
      "Connecting to database raw_flight_data\n",
      "Found tables: ['flights_2003_1', 'flights_2003_10', 'flights_2003_11', 'flights']\n",
      "flights already exists. Update? y/n: n\n"
     ]
    }
   ],
   "source": [
    "data = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airtime      0\n",
       "distance     0\n",
       "cancelled    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'quarter', 'month', 'dayofmonth', 'dayofweek', 'flightdate',\n",
       "       'reporting_airline', 'tail_number', 'flight_number_reporting_airline',\n",
       "       'originairportid', 'origincitymarketid', 'origin', 'origincityname',\n",
       "       'originstate', 'originstatename', 'destairportid', 'destcitymarketid',\n",
       "       'dest', 'destcityname', 'deststate', 'deststatename', 'crsdeptime',\n",
       "       'deptime', 'depdelay', 'depdelayminutes', 'depdel15',\n",
       "       'departuredelaygroups', 'deptimeblk', 'crsarrtime', 'arrtime',\n",
       "       'arrdelay', 'arrdelayminutes', 'arrdel15', 'arrivaldelaygroups',\n",
       "       'arrtimeblk', 'cancelled', 'cancellationcode', 'diverted',\n",
       "       'crselapsedtime', 'actualelapsedtime', 'airtime', 'flights', 'distance',\n",
       "       'distancegroup', 'carrierdelay', 'weatherdelay', 'nasdelay',\n",
       "       'securitydelay', 'lateaircraftdelay'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorter_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightdate</th>\n",
       "      <th>cancellations</th>\n",
       "      <th>flights</th>\n",
       "      <th>canc_rate</th>\n",
       "      <th>avg_canc_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-04</td>\n",
       "      <td>0</td>\n",
       "      <td>250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-05</td>\n",
       "      <td>0</td>\n",
       "      <td>264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-06</td>\n",
       "      <td>4</td>\n",
       "      <td>283</td>\n",
       "      <td>0.014134</td>\n",
       "      <td>0.014134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-01-07</td>\n",
       "      <td>4</td>\n",
       "      <td>275</td>\n",
       "      <td>0.014545</td>\n",
       "      <td>0.014545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-01-08</td>\n",
       "      <td>12</td>\n",
       "      <td>273</td>\n",
       "      <td>0.043956</td>\n",
       "      <td>0.043956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flightdate  cancellations  flights  canc_rate  avg_canc_rate\n",
       "0 2003-01-04              0      250   0.000000       0.000000\n",
       "1 2003-01-05              0      264   0.000000       0.000000\n",
       "2 2003-01-06              4      283   0.014134       0.014134\n",
       "3 2003-01-07              4      275   0.014545       0.014545\n",
       "4 2003-01-08             12      273   0.043956       0.043956"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT \n",
    "    flightdate, \n",
    "    SUM(cancelled) AS cancellations,\n",
    "    COUNT(cancelled) AS flights,\n",
    "    SUM(cancelled)/CAST(COUNT(cancelled) AS FLOAT) AS canc_rate,\n",
    "    AVG(cancelled) AS avg_canc_rate\n",
    "FROM flights\n",
    "WHERE \n",
    "    origin = 'SEA' AND\n",
    "    flightdate > '2003-01-03'\n",
    "GROUP BY flightdate\n",
    "ORDER BY flightdate\n",
    "LIMIT 5\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(q, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightdate</th>\n",
       "      <th>lag_cancellations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-01-04</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-01-05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003-01-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003-01-07</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003-01-08</td>\n",
       "      <td>0.003745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003-01-09</td>\n",
       "      <td>0.010526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003-01-10</td>\n",
       "      <td>0.006993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2003-01-11</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2003-01-12</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2003-01-13</td>\n",
       "      <td>0.014134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2003-01-14</td>\n",
       "      <td>0.014545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2003-01-15</td>\n",
       "      <td>0.043956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   flightdate  lag_cancellations\n",
       "0  2003-01-01                NaN\n",
       "1  2003-01-02                NaN\n",
       "2  2003-01-03                NaN\n",
       "3  2003-01-04                NaN\n",
       "4  2003-01-05                NaN\n",
       "5  2003-01-06                NaN\n",
       "6  2003-01-07                NaN\n",
       "7  2003-01-08           0.003745\n",
       "8  2003-01-09           0.010526\n",
       "9  2003-01-10           0.006993\n",
       "10 2003-01-11           0.000000\n",
       "11 2003-01-12           0.000000\n",
       "12 2003-01-13           0.014134\n",
       "13 2003-01-14           0.014545\n",
       "14 2003-01-15           0.043956"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def prev_average(n):\n",
    "    \"\"\"\n",
    "    Returns average cancellation rate of n days ago\n",
    "    \"\"\"\n",
    "    q = f\"\"\"\n",
    "    SELECT \n",
    "        flightdate,\n",
    "        LAG(AVG(cancelled), {n}) OVER(ORDER BY flightdate) AS lag_cancellations\n",
    "    FROM flights\n",
    "    WHERE \n",
    "        origin = 'SEA'\n",
    "    GROUP BY flightdate\n",
    "    ORDER BY flightdate\n",
    "    LIMIT 15;\n",
    "    \"\"\"\n",
    "    return pd.read_sql(q, engine)\n",
    "prev_average(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightdate</th>\n",
       "      <th>make_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>2003-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>2003-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-01-03</td>\n",
       "      <td>2003-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-01-04</td>\n",
       "      <td>2003-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-01-05</td>\n",
       "      <td>2003-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flightdate   make_date\n",
       "0 2003-01-01  2003-01-01\n",
       "1 2003-01-02  2003-01-02\n",
       "2 2003-01-03  2003-01-03\n",
       "3 2003-01-04  2003-01-04\n",
       "4 2003-01-05  2003-01-05"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT \n",
    "    flightdate,\n",
    "    make_date(year, month, dayofmonth)\n",
    "FROM flights LIMIT 5;\n",
    "\"\"\"\n",
    "pd.read_sql(q, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>quarter</th>\n",
       "      <th>month</th>\n",
       "      <th>dayofmonth</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>flightdate</th>\n",
       "      <th>reporting_airline</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>flight_number_reporting_airline</th>\n",
       "      <th>originairportid</th>\n",
       "      <th>...</th>\n",
       "      <th>actualelapsedtime</th>\n",
       "      <th>airtime</th>\n",
       "      <th>flights</th>\n",
       "      <th>distance</th>\n",
       "      <th>distancegroup</th>\n",
       "      <th>carrierdelay</th>\n",
       "      <th>weatherdelay</th>\n",
       "      <th>nasdelay</th>\n",
       "      <th>securitydelay</th>\n",
       "      <th>lateaircraftdelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2003-01-01</td>\n",
       "      <td>NW</td>\n",
       "      <td>N530US</td>\n",
       "      <td>155</td>\n",
       "      <td>13487</td>\n",
       "      <td>...</td>\n",
       "      <td>224</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2003-01-02</td>\n",
       "      <td>NW</td>\n",
       "      <td>N533US</td>\n",
       "      <td>155</td>\n",
       "      <td>13487</td>\n",
       "      <td>...</td>\n",
       "      <td>239</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2003-01-03</td>\n",
       "      <td>NW</td>\n",
       "      <td>N503US</td>\n",
       "      <td>155</td>\n",
       "      <td>13487</td>\n",
       "      <td>...</td>\n",
       "      <td>242</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2003-01-04</td>\n",
       "      <td>NW</td>\n",
       "      <td>N529US</td>\n",
       "      <td>155</td>\n",
       "      <td>13487</td>\n",
       "      <td>...</td>\n",
       "      <td>226</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>2003-01-05</td>\n",
       "      <td>NW</td>\n",
       "      <td>N545US</td>\n",
       "      <td>155</td>\n",
       "      <td>13487</td>\n",
       "      <td>...</td>\n",
       "      <td>227</td>\n",
       "      <td>182</td>\n",
       "      <td>1</td>\n",
       "      <td>1399</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  quarter  month  dayofmonth  dayofweek flightdate reporting_airline  \\\n",
       "0  2003        1      1           1          3 2003-01-01                NW   \n",
       "1  2003        1      1           2          4 2003-01-02                NW   \n",
       "2  2003        1      1           3          5 2003-01-03                NW   \n",
       "3  2003        1      1           4          6 2003-01-04                NW   \n",
       "4  2003        1      1           5          7 2003-01-05                NW   \n",
       "\n",
       "  tail_number flight_number_reporting_airline originairportid  ...  \\\n",
       "0      N530US                             155           13487  ...   \n",
       "1      N533US                             155           13487  ...   \n",
       "2      N503US                             155           13487  ...   \n",
       "3      N529US                             155           13487  ...   \n",
       "4      N545US                             155           13487  ...   \n",
       "\n",
       "  actualelapsedtime airtime flights distance distancegroup carrierdelay  \\\n",
       "0               224     200       1     1399             6         None   \n",
       "1               239     205       1     1399             6         None   \n",
       "2               242     220       1     1399             6         None   \n",
       "3               226     198       1     1399             6         None   \n",
       "4               227     182       1     1399             6         None   \n",
       "\n",
       "  weatherdelay nasdelay securitydelay lateaircraftdelay  \n",
       "0         None     None          None              None  \n",
       "1         None     None          None              None  \n",
       "2         None     None          None              None  \n",
       "3         None     None          None              None  \n",
       "4         None     None          None              None  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT * FROM flights LIMIT 5\"\"\"\n",
    "pd.read_sql(q, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.GroupingError) column \"flights.flight_number_reporting_airline\" must appear in the GROUP BY clause or be used in an aggregate function\nLINE 3:     CAST(flightdate AS DATE) || '_fl' || flight_number_repor...\n                                                 ^\n\n[SQL: \nSELECT\n    CAST(flightdate AS DATE) || '_fl' || flight_number_reporting_airline\n        AS flight,\n    flightdate,\n    dayofweek,\n    airtime,\n    distance,\n    LAG(AVG(cancelled), 1) OVER(\n        ORDER BY flightdate) AS avg_cancellations_1,\n    cancelled\nFROM flights\nGROUP BY flightdate\nLIMIT 5;\n]\n(Background on this error at: http://sqlalche.me/e/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGroupingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1243\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1244\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m                     )\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGroupingError\u001b[0m: column \"flights.flight_number_reporting_airline\" must appear in the GROUP BY clause or be used in an aggregate function\nLINE 3:     CAST(flightdate AS DATE) || '_fl' || flight_number_repor...\n                                                 ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-346-cd32152ab3dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mLIMIT\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \"\"\"\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             chunksize=chunksize)\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     def read_table(self, table_name, index_col=None, coerce_float=True,\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \"\"\"\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_text\u001b[0;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m         )\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1248\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m             )\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_from_cause\u001b[0;34m(exception, exc_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mcause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb, cause)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1244\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m                     )\n\u001b[1;32m   1246\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.errors.GroupingError) column \"flights.flight_number_reporting_airline\" must appear in the GROUP BY clause or be used in an aggregate function\nLINE 3:     CAST(flightdate AS DATE) || '_fl' || flight_number_repor...\n                                                 ^\n\n[SQL: \nSELECT\n    CAST(flightdate AS DATE) || '_fl' || flight_number_reporting_airline\n        AS flight,\n    flightdate,\n    dayofweek,\n    airtime,\n    distance,\n    LAG(AVG(cancelled), 1) OVER(\n        ORDER BY flightdate) AS avg_cancellations_1,\n    cancelled\nFROM flights\nGROUP BY flightdate\nLIMIT 5;\n]\n(Background on this error at: http://sqlalche.me/e/f405)"
     ]
    }
   ],
   "source": [
    "# Design matrix\n",
    "dm = \"\"\"\n",
    "SELECT\n",
    "    CAST(flightdate AS DATE) || '_fl' || flight_number_reporting_airline\n",
    "        AS flight,\n",
    "    flightdate,\n",
    "    dayofweek,\n",
    "    airtime,\n",
    "    distance,\n",
    "    LAG(AVG(cancelled), 1) OVER(\n",
    "        ORDER BY flightdate) AS avg_cancellations_1,\n",
    "    cancelled\n",
    "FROM flights\n",
    "GROUP BY flightdate\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "pd.read_sql(dm, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>airtime</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flight</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2003-01-01_fl155</th>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>1399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-02_fl155</th>\n",
       "      <td>4</td>\n",
       "      <td>205</td>\n",
       "      <td>1399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-03_fl155</th>\n",
       "      <td>5</td>\n",
       "      <td>220</td>\n",
       "      <td>1399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-04_fl155</th>\n",
       "      <td>6</td>\n",
       "      <td>198</td>\n",
       "      <td>1399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003-01-05_fl155</th>\n",
       "      <td>7</td>\n",
       "      <td>182</td>\n",
       "      <td>1399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dayofweek  airtime  distance  cancelled\n",
       "flight                                                   \n",
       "2003-01-01_fl155          3      200      1399          0\n",
       "2003-01-02_fl155          4      205      1399          0\n",
       "2003-01-03_fl155          5      220      1399          0\n",
       "2003-01-04_fl155          6      198      1399          0\n",
       "2003-01-05_fl155          7      182      1399          0"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Design matrix\n",
    "dm = \"\"\"\n",
    "SELECT\n",
    "    CAST(flightdate AS DATE) || '_fl' || flight_number_reporting_airline\n",
    "        AS flight,\n",
    "    dayofweek,\n",
    "    airtime,\n",
    "    distance,\n",
    "    cancelled\n",
    "FROM flights\n",
    "LIMIT 5;\n",
    "\"\"\"\n",
    "pd.read_sql(dm, engine, index_col='flight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.GroupingError) column \"d.flights\" must appear in the GROUP BY clause or be used in an aggregate function\nLINE 14:     SUM(cancellations) / SUM(CAST(flights AS FLOAT))\n                                           ^\n\n[SQL: \nWITH daily AS (\n    SELECT \n        flightdate, \n        SUM(cancelled) AS cancellations,\n        COUNT(cancelled) AS flights\n    FROM flights\n    WHERE origin = 'SEA'\n    GROUP BY flightdate\n    ORDER BY flightdate\n)\n\nSELECT \n    SUM(cancellations) / SUM(CAST(flights AS FLOAT))\n        OVER(\n            ORDER BY flightdate\n            RANGE BETWEEN '30 day' PRECEDING AND '1 day' PRECEDING)\n        AS canc_rate\nFROM daily d\nWHERE \n    flightdate > '2003-01-29'\nGROUP BY flightdate\nORDER BY flightdate\nLIMIT 15\n;\n]\n(Background on this error at: http://sqlalche.me/e/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGroupingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1243\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1244\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m                     )\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mGroupingError\u001b[0m: column \"d.flights\" must appear in the GROUP BY clause or be used in an aggregate function\nLINE 14:     SUM(cancellations) / SUM(CAST(flights AS FLOAT))\n                                           ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-303-ba237ad04991>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \"\"\"\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparse_dates\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m             chunksize=chunksize)\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1099\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1100\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    988\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnectable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m     def read_table(self, table_name, index_col=None, coerce_float=True,\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2166\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2168\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \"\"\"\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_text\u001b[0;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m             \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1155\u001b[0;31m             \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1156\u001b[0m         )\n\u001b[1;32m   1157\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_events\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1247\u001b[0m             self._handle_dbapi_exception(\n\u001b[0;32m-> 1248\u001b[0;31m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1249\u001b[0m             )\n\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1464\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1465\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1466\u001b[0;31m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_cause\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1467\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_from_cause\u001b[0;34m(exception, exc_info)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mcause\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mexc_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m     \u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_tb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcause\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb, cause)\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__cause__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcause\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1242\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1243\u001b[0m                     self.dialect.do_execute(\n\u001b[0;32m-> 1244\u001b[0;31m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1245\u001b[0m                     )\n\u001b[1;32m   1246\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/project3/lib/python3.6/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mProgrammingError\u001b[0m: (psycopg2.errors.GroupingError) column \"d.flights\" must appear in the GROUP BY clause or be used in an aggregate function\nLINE 14:     SUM(cancellations) / SUM(CAST(flights AS FLOAT))\n                                           ^\n\n[SQL: \nWITH daily AS (\n    SELECT \n        flightdate, \n        SUM(cancelled) AS cancellations,\n        COUNT(cancelled) AS flights\n    FROM flights\n    WHERE origin = 'SEA'\n    GROUP BY flightdate\n    ORDER BY flightdate\n)\n\nSELECT \n    SUM(cancellations) / SUM(CAST(flights AS FLOAT))\n        OVER(\n            ORDER BY flightdate\n            RANGE BETWEEN '30 day' PRECEDING AND '1 day' PRECEDING)\n        AS canc_rate\nFROM daily d\nWHERE \n    flightdate > '2003-01-29'\nGROUP BY flightdate\nORDER BY flightdate\nLIMIT 15\n;\n]\n(Background on this error at: http://sqlalche.me/e/f405)"
     ]
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "WITH daily AS (\n",
    "    SELECT \n",
    "        flightdate, \n",
    "        SUM(cancelled) AS cancellations,\n",
    "        COUNT(cancelled) AS flights\n",
    "    FROM flights\n",
    "    WHERE origin = 'SEA'\n",
    "    GROUP BY flightdate\n",
    "    ORDER BY flightdate\n",
    ")\n",
    "\n",
    "SELECT \n",
    "    SUM(cancellations) / SUM(CAST(flights AS FLOAT))\n",
    "        OVER(\n",
    "            ORDER BY flightdate\n",
    "            RANGE BETWEEN '30 day' PRECEDING AND '1 day' PRECEDING)\n",
    "        AS canc_rate\n",
    "FROM daily d\n",
    "WHERE \n",
    "    flightdate > '2003-01-29'\n",
    "GROUP BY flightdate\n",
    "ORDER BY flightdate\n",
    "LIMIT 15\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(q, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flightdate</th>\n",
       "      <th>avg_cancellations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003-02-03</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flightdate avg_cancellations\n",
       "0 2003-02-03              None\n",
       "1 2003-02-03              None\n",
       "2 2003-02-03              None\n",
       "3 2003-02-03              None\n",
       "4 2003-02-03              None\n",
       "5 2003-02-03              None\n",
       "6 2003-02-03              None\n",
       "7 2003-02-03              None\n",
       "8 2003-02-03              None\n",
       "9 2003-02-03              None"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT \n",
    "    flightdate, \n",
    "    AVG(cancelled)\n",
    "        OVER(\n",
    "            PARTITION BY flightdate\n",
    "            ORDER BY flightdate \n",
    "            RANGE BETWEEN '30 days' PRECEDING AND '1 days' PRECEDING\n",
    "                )  AS avg_cancellations\n",
    "FROM flights\n",
    "WHERE origin = 'SEA' AND\n",
    "    flightdate > '2003-02-02'\n",
    "ORDER BY flightdate\n",
    "LIMIT 10\n",
    ";\n",
    "\"\"\"\n",
    "\n",
    "pd.read_sql(q, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Before moving on to exploratory analysis, write down some notes about challenges encountered while working with this data that might be helpful for anyone else (including yourself) who may work through this later on.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the Data\n",
    "\n",
    "*Before you start exploring the data, write out your thought process about what you're looking for and what you expect to find. Take a minute to confirm that your plan actually makes sense.*\n",
    "\n",
    "*Calculate summary statistics and plot some charts to give you an idea what types of useful relationships might be in your dataset. Use these insights to go back and download additional data or engineer new features if necessary. Not now though... remember we're still just trying to finish the MVP!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/visualization/visualize.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    # data = load_features('data/processed')\n",
    "    # describe_features(data, 'reports/')\n",
    "    # generate_charts(data, 'reports/figures/')\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What did you learn? What relationships do you think will be most helpful as you build your model?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the Data\n",
    "\n",
    "*Describe the algorithm or algorithms that you plan to use to train with your data. How do these algorithms work? Why are they good choices for this data and problem space?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/train_model.py\n",
    "\n",
    "# Imports\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit, cross_validate\n",
    "from sklearn import ensemble, metrics, neighbors, neural_network, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Helper functions\n",
    "def save_to(filepath, item):\n",
    "    \"\"\"\n",
    "    Pickles item sand saves it to path\n",
    "    Input: object to be pickled, string containing directory and filename\n",
    "    Output: pickled object stored to provided path\n",
    "    \"\"\"\n",
    "    with open(filepath, 'wb') as to_write:\n",
    "        pickle.dump(item, to_write)\n",
    "    return\n",
    "\n",
    "\n",
    "def build_model(model):\n",
    "    \"\"\"\n",
    "    Instantiates model\n",
    "    Input: model (str), name of model to instantiate\n",
    "    Output: instantiated model\n",
    "    Model options are:\n",
    "        'Logistic Regression',\n",
    "        'Naive Bayes',\n",
    "        'Linear SVM',\n",
    "        'Linear MLP',\n",
    "        'KNN',\n",
    "        'Random Forest',\n",
    "        'Radial SVM',\n",
    "        'Relu MLP'\n",
    "    \"\"\"\n",
    "    models = {\n",
    "        'Logistic Regression': LogisticRegression(solver='lbfgs'),\n",
    "        'Naive Bayes':GaussianNB(),\n",
    "        'Linear SVM': svm.LinearSVC(),\n",
    "        'Linear MLP': neural_network.MLPClassifier(activation=\"identity\"),\n",
    "        'KNN': neighbors.KNeighborsClassifier(),\n",
    "        'Random Forest': ensemble.RandomForestClassifier(n_estimators=100),\n",
    "        'Radial SVM': svm.SVC(gamma=\"scale\"),\n",
    "        'Relu MLP': neural_network.MLPClassifier()\n",
    "    }\n",
    "    return models[model]\n",
    "\n",
    "\n",
    "def save_train_test(cv_train, cv_test, train, test, path):\n",
    "    \"\"\"\n",
    "    Saves train and test data to pickles\n",
    "    Input: train and test data and path to store pickles in\n",
    "    Output: pickled files in directory\n",
    "    \"\"\"\n",
    "    save_to(path + 'cv_train.pkl', cv_train)\n",
    "    save_to(path + 'cv_test.pkl', cv_test)\n",
    "    save_to(path + 'train.pkl', train)\n",
    "    save_to(path + 'test.pkl', test)\n",
    "    pass\n",
    "\n",
    "\n",
    "def train_test_split(df):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#     tscv = TimeSeriesSplit(n_splits=2)\n",
    "#     train_index, test_index = tscv.split(df)\n",
    "    n = df.shape[0]\n",
    "    cv_train, cv_test = df.iloc[:n//3], df.iloc[n//3 : 2*n//3]\n",
    "    train, test = df.iloc[:2*n//3], df.iloc[2*n//3:]\n",
    "    \n",
    "    return cv_train, cv_test, train, test\n",
    "    \n",
    "    \n",
    "def load_features(filepath):\n",
    "    \"\"\"\n",
    "    Loads data from csv and returns as dataframe\n",
    "    Input: relative filepath pointing to file\n",
    "    Output: dataframe containing data from csv\n",
    "    \"\"\"\n",
    "    data = pd.read_pickle(filepath)\n",
    "    return data\n",
    "\n",
    "\n",
    "def run(method='Logistic Regression'):\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    data = load_features('../data/processed/data.pkl')\n",
    "    cv_train, cv_test, train, test = train_test_split(data)\n",
    "    save_train_test(cv_train, cv_test, train, test, '../data/processed/')\n",
    "    model = build_model(method)\n",
    "    target = 'cancelled'\n",
    "    X_train, y_train = cv_train.drop(target, axis=1), cv_train[target]\n",
    "    model.fit(X_train, y_train)\n",
    "    save_to('../models/model.pkl', model)\n",
    "    \n",
    "    # Prediction time\n",
    "    X_test, y_test = cv_test.drop(target, axis=1), cv_test[target]\n",
    "    predictions = model.predict(X_test)\n",
    "    f1_score = metrics.f1_score(y_test, predictions)\n",
    "    print(f'F1 score of {f1_score} with model {method}')\n",
    "#     metrics = evaluate(cv_test, predictions)\n",
    "    # save_metrics('reports/')\n",
    "    return data, model, cv_test, X_test, y_test, predictions, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of 0.0 with model Logistic Regression\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "data, model, cv_test, X_test, y_test, predictions, f1_score = run('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crselapsedtime</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancelled</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>flight</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-09-01_fl24</th>\n",
       "      <td>312.0</td>\n",
       "      <td>2496</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-07_fl346</th>\n",
       "      <td>163.0</td>\n",
       "      <td>954</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-04_fl690</th>\n",
       "      <td>60.0</td>\n",
       "      <td>224</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-03_fl608</th>\n",
       "      <td>144.0</td>\n",
       "      <td>867</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-23_fl901</th>\n",
       "      <td>88.0</td>\n",
       "      <td>399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-24_fl767</th>\n",
       "      <td>361.0</td>\n",
       "      <td>2335</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-17_fl38</th>\n",
       "      <td>354.0</td>\n",
       "      <td>2717</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-04_fl1085</th>\n",
       "      <td>278.0</td>\n",
       "      <td>1721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-07-20_fl319</th>\n",
       "      <td>122.0</td>\n",
       "      <td>696</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-30_fl3837</th>\n",
       "      <td>81.0</td>\n",
       "      <td>228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  crselapsedtime  distance  cancelled\n",
       "flight                                               \n",
       "2017-09-01_fl24            312.0      2496          0\n",
       "2018-10-07_fl346           163.0       954          0\n",
       "2017-08-04_fl690            60.0       224          1\n",
       "2017-08-03_fl608           144.0       867          0\n",
       "2018-02-23_fl901            88.0       399          0\n",
       "2018-01-24_fl767           361.0      2335          0\n",
       "2018-03-17_fl38            354.0      2717          0\n",
       "2018-02-04_fl1085          278.0      1721          0\n",
       "2017-07-20_fl319           122.0       696          0\n",
       "2018-10-30_fl3837           81.0       228          0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197652, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    196495\n",
       "1      1157\n",
       "Name: cancelled, dtype: int64"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(cv_test.sample(10))\n",
    "print(cv_test.shape)\n",
    "cv_test['cancelled'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of 0.0 with model Logistic Regression\n",
      "CPU times: user 2.65 s, sys: 182 ms, total: 2.83 s\n",
      "Wall time: 1.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of 0.0 with model Naive Bayes\n",
      "CPU times: user 1.52 s, sys: 177 ms, total: 1.69 s\n",
      "Wall time: 976 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/svm/base.py:931: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n",
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of 0.0 with model Linear SVM\n",
      "CPU times: user 28.6 s, sys: 244 ms, total: 28.9 s\n",
      "Wall time: 28.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of 0.0 with model Linear MLP\n",
      "CPU times: user 17.4 s, sys: 383 ms, total: 17.8 s\n",
      "Wall time: 5.07 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of 0.0 with model KNN\n",
      "CPU times: user 7.44 s, sys: 268 ms, total: 7.71 s\n",
      "Wall time: 6.77 s\n",
      "F1 score of 0.0 with model Random Forest\n",
      "CPU times: user 12.7 s, sys: 398 ms, total: 13.1 s\n",
      "Wall time: 10.9 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score of 0.0 with model Radial SVM\n",
      "CPU times: user 19.2 s, sys: 394 ms, total: 19.6 s\n",
      "Wall time: 18.7 s\n",
      "F1 score of 0.0 with model Relu MLP\n",
      "CPU times: user 49.4 s, sys: 563 ms, total: 50 s\n",
      "Wall time: 13.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "methods = [\n",
    "    'Logistic Regression',\n",
    "    'Naive Bayes',\n",
    "    'Linear SVM',\n",
    "    'Linear MLP',\n",
    "    'KNN',\n",
    "    'Random Forest',\n",
    "    'Radial SVM',\n",
    "    'Relu MLP']\n",
    "for method in methods:\n",
    "    %time run(method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25 µs, sys: 1e+03 ns, total: 26 µs\n",
      "Wall time: 41.2 µs\n",
      "CPU times: user 41 µs, sys: 3 µs, total: 44 µs\n",
      "Wall time: 48.2 µs\n",
      "CPU times: user 87 µs, sys: 1e+03 ns, total: 88 µs\n",
      "Wall time: 93.9 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.780301787479031"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.linspace(0, 10*4)\n",
    "%time x.sum()\n",
    "%time x.mean()\n",
    "%time x.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [],
   "source": [
    "## %%writefile ../src/models/predict_model.py\n",
    "\n",
    "# imports\n",
    "# helper functions go here\n",
    "def load_pickle(filepath):\n",
    "    \"\"\"\n",
    "    Opens pickled object stored at filepath\n",
    "    Input: string containing directory and filename\n",
    "    Output: pickled object stored to provided path\n",
    "    \"\"\"\n",
    "    with open(filepath, 'rb') as p:\n",
    "        item = pickle.load(p)\n",
    "    return item\n",
    "\n",
    "def load_data(filepath):\n",
    "    \"\"\"\n",
    "    Loads data from csv and returns as dataframe\n",
    "    Input: relative filepath pointing to file\n",
    "    Output: dataframe containing data from csv\n",
    "    \"\"\"\n",
    "    data = pd.read_pickle(filepath)\n",
    "    return data\n",
    "\n",
    "def load_test_data(path):\n",
    "    \"\"\"\n",
    "    Saves train and test data to pickles\n",
    "    Input: train and test data and path to store pickles in\n",
    "    Output: pickled files in directory\n",
    "    \"\"\"\n",
    "    cv_train = load_data(path + 'cv_train.pkl')\n",
    "    cv_test = load_data(path + 'cv_test.pkl')\n",
    "    train = load_data(path + 'train.pkl')\n",
    "    test = load_data(path + 'test.pkl')\n",
    "    return cv_train, cv_test, train, test\n",
    "\n",
    "\n",
    "def run():\n",
    "    \"\"\"\n",
    "    Executes a set of helper functions that read files from data/processed,\n",
    "    calculates descriptive statistics for the population, and plots charts\n",
    "    that visualize interesting relationships between features.\n",
    "    \"\"\"\n",
    "    target = 'cancelled'\n",
    "    cv_train, cv_test, train, test = load_test_data('../data/processed/')\n",
    "    trained_model = load_pickle('../models/model.pkl')\n",
    "    X_test, y_test = cv_test.drop(target, axis=1), cv_test[target]\n",
    "    predictions = trained_model.predict(X_test)\n",
    "    f1_score = metrics.f1_score(y_test, predictions)\n",
    "#     metrics = evaluate(cv_test, predictions)\n",
    "    # save_metrics('reports/')\n",
    "    return y_test, predictions, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/project3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "y_test, predictions, f1_score = run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    196495\n",
       "1      1157\n",
       "Name: cancelled, dtype: int64"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    197652\n",
       "dtype: int64"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Write down any thoughts you may have about working with these algorithms on this data. What other ideas do you want to try out as you iterate on this pipeline?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret the Model\n",
    "\n",
    "_Write up the things you learned, and how well your model performed. Be sure address the model's strengths and weaknesses. What types of data does it handle well? What types of observations tend to give it a hard time? What future work would you or someone reading this might want to do, building on the lessons learned and tools developed in this project?_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (project3)",
   "language": "python",
   "name": "project3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "288.889px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
